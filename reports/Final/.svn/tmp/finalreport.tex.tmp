\documentclass[11pt,a4paper]{report}
\usepackage[left=2.5cm,right=2cm,top=2cm,bottom=2cm]{geometry}
\usepackage[pdftex]{graphicx}

%\usepackage[nottoc,numbib]{tocbibind}
\usepackage{listings}
\usepackage{cite}
\usepackage{tocloft}
\usepackage{parskip}

%Preset style for all code listings is C
\lstset{language = C}


\setcounter{tocdepth}{3}
\addtocontents{toc}{\protect\vspace{10pt}}
\addcontentsline{toc}{chapter}{Bibliography}
\renewcommand{\cftsecleader}{\cftdotfill{\cftdotsep}}


\setlength{\parindent}{0cm}

\begin{document}
\input{./titlepage.tex}




\section*{Abstract}
With the onset of multi-core processors, writing software that takes advantage of such processors has become an essential part of modern software development. Unfortunately, writing concurrent programs is a difficult task and often produces many bugs which will not be found even after extensive testing. There are many scenarios such as data races and deadlocks that will go unnoticed until a system has gone to production, potentially leading to catastrophic results. To overcome this, many tools that trace concurrent execution have been created to debug concurrent software.

An existing tool KLEE-THREADS uses symbolic execution to trace concurrency bugs and output a thread schedule to show the conditions for the bug to arise.

Concurrency bugs are notoriously difficult to reproduce, since many bugs are dependent on a particular thread schedule that occurs only very rarely. The aim of this project has been to provide deterministic replay to concurrent software.

This tool takes a schedule generated by KLEE-THREADS and generates an executable in which the thread schedule will be followed. KLEE-THREADS achieves its schedule via symbolic execution. This tool provides a replay feature via function interposition. 

The tool works with the original Pthreads API and requires no extra-intervention on the part of the programmer. It incurs a minimal overhead and will follow any generated schedule accurately.

The Pthreads API is very large. As a result of this, I have been unable to implement a replay feature for the whole library. Instead, I have focused on three key aspects on the API: thread creation, thread termination, and mutex locking and unlocking. I have made a higly robust deterministic replay tool for these parts of the Pthreads API.

I have implemented the final tool by using function interposition. The tool will load my library and execute a binary that uses Pthreads while forcing the thread schedule it has been passed to be followed. It operates in two modes. In its first mode, the tool will force the schedule and either hang or finish exeuction at the end of the schedule. In its second mode, the tool will follow the schedule until its end and then resume normal execution with no further intervention. This allows a schedule to be followed to a certain point and then program execution to be observed from that point onwards.


\newpage

\section*{Acknowledgements}


\newpage


\tableofcontents

\newpage
\clearpage

\chapter{Introduction}
Multi-core processors have moved from specialist computers and large-scale clusters to desktop and laptop computers and are becoming the norm in all areas of computing. The need to make use of multiple processors in software development has become essential and this had led to many new types of bugs emerging.

\section{Deterministic Replay}

The aim of this project has been to create a tool that provide deterministic replay to concurrent software written using the Pthreads API. Deterministic replay is used  to force a program to follow a certain path of execution. By reproducing a particular execution trace, a programmer is able to see an error that might not occur under normal conditions. Many bugs in concurrent software rely on a very specific thread schedule before they will occur. As a result of this, many such bugs will not appear even after thousands of executions. Deterministic replay will force a particular schedule to be followed and reproduce the circumstances that gave rise to the bug, thus allowing the programmer to quickly and accurately debug their software.

For deterministic replay to be successful, a thread schedule must be captured from a given program. Once the thread schedule has been captured, deterministic replay becomes possible by forcing the schedule to be followed. The tool presented in this paper uses an existing replay tool KLEETHREADS for detecting concurrency bugs in concurrent C programs that use the Pthreads API. The tool that is being presented takes a schedule from KLEETHREADS and then follows the path of execution as determined by the passed schedule.

The Pthreads API is a particularly large API and as a result of its size, I have not been able to implement deterministic replay for the whole API. Instead, I have focused on creating a robust tool to work with thread creation, thread joining, mutex locking and unlocking, and waiting on conditions signalling and notifying sleeping threads.


\section{Motivation}
Software bugs remain a major source of annoyance for software developers and with the advent of multi-core processors and the need to write concurrent software, new, more devastating bugs have arisen. These bugs are often difficult to track down and occur only under very specific conditions which might not arise even after extensive testing and executions. To ease the tracing of such bugs, many tools which provide execution traces by a number of techniques have been created.

One such tool KLEETHREADS, uses instrumentation to trace concurrency bugs in  concurrent C programs. While KLEETHREADS has proved excellent in tracing bugs, it does not support a replay feature to show programmers the bugs which it traces. The motivation behind this project has been to provide such a tool.

The main motivation for creating the tool is to add a deterministic replay feature to the KLEETHREADS tool which already provides a bug trace feature to the Pthreads API.

Programmers can often be sceptical about schedules they are shown which lead to bugs. Tools like \textsf{gdb} and other popular debuggers can often slow down execution and prevent bugs from occurring in the way that the schedule determined. By adding a deterministic replay feature to the KLEETHREADS tool, we will be able to show programmers the conditions under which their bug arises and demonstrate to them how to fix it.

By showing a programmer a bug quickly and allowing them to recreate the exact conditions under which the bug occurred, we will be able to speed up the debugging process significantly as through a combination of the schedules output by KLEETHREADS and the deterministic replay provided by this tool it is simple to detect, trace and fix bugs quickly and efficiently.

It is also desirable to create replay feature for a program without having to alter the original source code. This way the programmer can simply run the tool using their program and feed the tool a schedule. The tool will then follow this schedule faithfully to reproduce the conditions under which the bug occurred. By requiring no modification of the original executable, a user is able to use the tool with ease.

Some deterministic replay tools, however, achieve deterministic execution in non-deterministic programs but incur a large overhead. Ideally, a tool should incur as little overhead as possible. A tool that produces a large space and time overhead can be inconvenient to use and sometime traces may be so large that such tools will run out of memory before finishing the execution replay.


\section{Objectives}

The objectives for the project are as follows:

\begin{itemize}
\item
To provide a tool that takes schedules produce by KLEETHREADS and accurately forces the thread schedules to be followed.
\item
To create two modes of execution for the tool. One to simply follow a schedule and either hang or terminate execution depending on its current state. Two to follow a schedule either to its end or an arbitrary point and then resume normal execution so that results can be observed from a certain point.
\item
To create the tool such that it can be run with the original executables, so that no source-code level modifications are required and such that no re-linking is required.
\item
To create the tool while incurring as minimal runtime overhead as possible so that large schedules can be followed with minimal memory footprints.
\end{itemize} 

\section{Contributions}

The contributions for the project have been as follows:

\begin{itemize}
\item
A novel way of using function interception within the Linux kernel to interpose Pthread functions and force thread schedules to be followed.
\item
A deterministic replay tool that can be run with the original executable and the original functions in the Pthreads API.
\item
A deterministic replay tool that incurs a minimal additional overhead by way of function intercepting using the LD\_PRELOAD environment variable.
\end{itemize}

\section{Results}
The results for the project have been promising. The tool works successfully with a large number of thread schedules output by the KLEETHREADS tool and successfully executes with minimal overhead on the original executable. The tool only requires an executable that uses the Pthread API as well as a thread schedule for it to follow. 

The tool does not have to be used exclusively with KLEETHREADS as it will force execution on any schedule it is passed. Thus a user can create their own schedules for the tool to follow and observe the output. In this way, the tool is truly a deterministic replay tool for C programs and does not rely on any specific replay feature to function correctly.

The main limitations of the project have been in the size of the Pthreads API and the amount of time allocated to complete the project as well as some portability issues. As a result of the size of the Pthreads API, I have been unable to integrate the tool with every aspect of the API. Instead, I have focused on creating a robust tool for thread creation, thread termination, mutex locking and unlocking, and waiting on and signalling condition variables. 

There have also been some portability limitations with the tool. While the tool is guaranteed to work with the Linux kernel, the use of pthread\_tryjoin\_np(...) in thread termination calls limits its portabiliy across other POSIX compliant platforms.

\vspace{3em}
Below is a list of the Pthread functions I have implemented:

\input{APITable.tex}

\newpage



\section{Structure of this Report}
The rest of this report is structured as follows: Chapter 2 present background and related work, as well as some of the inspirations for the tool. Chapter 3 discusses the approach that was taken to the creation of the tool and the key concepts of the implementation. Chapter 4 discussed the development process and the problems encountered along the way. Chapter 5 discusses the testing process and the evaluation of the tool. Finally, Chapter 6 summarizes the document and concludes the achievements made by the project and possible future work.

\chapter{Background and Related Work}
\section{Concurrency}
Concurrency can best be described as two or more things occurring at once, but not necessarily at the same time. It differs from parallelism (although the too are often used interchangeably) since concurrency allows thread interleaving while parallelism generally refers to two or more threads running simultaneously. 

Concurrency has become a major problem for the modern software developer and many programs are expected to have at least a basic level of concurrency support. The time for developers to simply rely on increased CPU performance to speed up their programs has come to an end \cite{Sutter}.

Writing concurrent software produces bugs that would not usually occur in single-threaded applications. The most obvious example of such a bug is a data race. Data races occur when multiple threads of execution alter the value of a variable in shared memory at the same time. The result is indeterminate and in such cases the programmer cannot know what the value of the variable will be ahead of time. Data races can be resolved using simple concurrency techniques such as mutexes but these can require expertise to use properly and in large systems there may be so many data races that is is possible for a programmer to find them all.

Another bug common in concurrent software is a deadlock. Deadlocks are particularly nasty, since they often occur when a programmer has already taken measures to avoid concurrency bugs such as data races. An obvious path to deadlock is failing to unlock a mutex after obtaining it and forcing other threads to wait on that mutex. 

Concurrency bugs are difficult to reason about and there may be many possible paths of executions that can be followed in a given program state. As a result of this, even after extensive debugging and testing there may still be bug's in a concurrent system that go unnoticed for long periods of time and applications may even ship with undetected concurrency bugs which can lead to serious complications. 

In recent times the need to have sophisticated debugging tools for concurrent software has increased. 

\section{Bug Detection}

There exist some tools which have been created to detect concurrency bugs using a variety of techniques. I give a brief outline and evaluation of each of these tools below.

\subsection{KLEE-THREADS}

KLEE-THREADS uses dynamic symbolic execution to detect data races in concurrent C programs.


\subsection{Helgrind}
Helgrind is a tool provided as part of the Valgrind tool suite for detecting synchronisation errors in C, C++ and Fortran programs that use the Pthreads API. It focuses on three key areas of error detection: misuses of the Pthreads API, potential deadlocks, and data races.

Helgrind works in conjunction with Valgrind so executes a users program within the Valgrind framework. It intercepts Pthreads function calls to check for misuses of the Pthreads API and reports the errors back to the user. It detects potential deadlocks by monitoring the order in which threads obtain locks and building a graph to represent this ordering. If it detects a cycle in the graph it has built then it will raise a deadlock warning. 

In order to detect data races, Helgrind uses the Eraser algorithm \cite{Savage}. It relies on the happens-before relation \cite{Lamport} to determine the expected ordering of data accesses. If, through its monitoring of variable accesses, Helgrind detects that the accesses are ordered by the happens-before relation then nothing is raised. If the accesses are not ordered by the happens-before relations, however, then Helgrind will signal a data race detection. The happens-before relation only provides partial ordering no total ordering -- that is that two variables are merely unordered with respect to each other.

Helgrind's main limitations are that at times it can output both false negatives -- undetected data races -- and false positives -- data races that may not actually be data races.  

\subsection{ThreadSanitizer}

ThreadSanitizer is part of the Google data-race-test too suit and is a data race detection tool that seeks to eliminate the false negatives and false positives that are output by Helgrind and create a more efficient concurrent bug detection tool. The Linux and Mac versions of the tool are based on Valgrind \cite{valgrind} and the Windows version is base on PIN \cite{PIN}.

ThreadSanitizer runs as part of the Valgrind tool suite and uses a hybrid algorithm as well as a pure happens-before mode for efficient data race detection \cite{tsan}. 

ThreadSanitizer's hybrid algorithm works by observing a program's execution as a sequence of events. The key events are memory access and synchronisation events. A state machine is also used to maintain the history of its observed events \cite{tsan}. ThreadSanitizer's hybrid algorithm will report more false positives but will also detect more races.

Since ThreadSanitizer can operate in different modes, different results will be observed from each execution instance. In pure happens-before mode less data races will be detected and the results are less predictable but it will only report false positives if the program is custom-lock free. The advantage of ThreadSaniztier's pure happens-before mode is that ThreadSanitizer will report all locks involved in a race while a classical pure happens-before mode us unaware of locks and thus can't include them in its report\cite{tsan}.

ThreadSanitizer's main advantage is that is uses an existing tool, Valgrind, to provide better bug detection features than Helgrind, as well as being able to be run in multiple modes.
 





\section{Record/Replay Tools}

Record/replay in concurrent software debuggers is a feature that is provided to record a trace to a bug and then replay the conditions under which the bug occurred with the aim of reproducing the bug.

There are existing tools which provide both a record and replay feature to finding concurrency bugs. Below I list some of these tools and evaluate their advantages and disadvantages. Most of these tools focus on the Java programming language and target the Java Virtual Machine.


\subsection{LEAP}
\textsf{LEAP's} general idea for tracing execution is to force each shared variable to record each thread access it has during a given execution \cite{Huang}. To achieve this it is required to precisely locate which variables can be considered shared. This is achieved by using a static field-based shared variable scheme to identify which variables are being accessed. 

\textsf{LEAP} relies on a transformer to provide instrumentation to an intermediate representation of Java bytecode. It does this by instrumenting critical areas of the bytecode and inserting calls to the \textsf{LEAP} API so that correct record and replay can be recorder by the tool \cite{Huang}.

\textsf{LEAP} handles its record feature by invoking the \textsf{LEAP} API on each critical event it has identified to record the ID of the thread performing the access into the access vector. Once program execution has finished, LEAP will output a replay driver consisting of the thread creation order list and the access vector list \cite{Huang}.

\textsf{LEAP's} replay feature works by associating each thread in the schedule with a semaphore maintained in a global data structure to allow each thread to be suspended and resumed on demand \cite{Huang} rather than having to rely on Java's built in multi-threading tools which would not be suitable for \textsf{LEAP's} replay implementation.

\textsf{LEAP} is successful in that it provides a high-level of concurrent bug reproducibility while incurring a fairly minimal runtime cost. Its main disadvantage, however, is the need to insert instrumented API calls into an intermediary bytecode, since this means it cannot be used with pre-compiled Java programs. Also neither the record part nor the replay part of the tool can be used independently, which limits the tool's usability.

\subsection{DejaVu}
\textsf{DejaVu} aims to provide a record/replay feature to the Java programming language by identifying a logical thread schedule which aims to make \textsf{DejaVu} more efficient \cite{DejaVu}.

A logical thread schedule consists of one or more thread schedules belonging to the same equivalence class. Schedules can be deemed equivalent if the physical thread schedule matches the ordering of shared variable accesses in a given execution \cite{DejaVu}. The information captured in a logical thread schedule is enough for \textsf{DejaVu} to reproduce the execution behaviour of a program during execution. 

\textsf{DejaVu} is modified a Java Virtual Machine that can provide deterministic replay to multi-threaded Java programs \cite{DejaVu}. This is a desirable feature since it means that the replay can be provided on existing Java bytecode with minimal overhead.

The main advantage of \textsf{DejaVu} is that it can be used with programs written in Java with no need for recompilation. The main disadvantage is that users wishing to \textsf{DejaVu} must use the virtual machine provided to debug their programs. 

\section{Other Approaches}

\subsection{Output Deterministic Replay}
\textsf{Output Deterministic Replay (ODR)} is a software only tool that targets a variety of software and provides a minimal overhead in its replay execution. It is written in C and x86-Assembler and aims to be a lightweight middleware for Linux programs \cite{ODR}.  

The main difference between \textsf{ODR} and other replay tools is its approach to replication of the original file. \textsf{ODR} provides only a low-fidelity replay system, rather than the structure deterministic approach other tools provide \cite{ODR}.

The \textit{output-failure replay problem} is to ensure that any failures which occur in the original run of a program are visible in the replay of the program \cite{ODR}. This is a different approach to deterministic replay since it provides guarantees about the final program state rather than the execution path, allowing multiple paths to be explored in a given replay provided they lead to the same output. Tis can expose bugs that might occur under numerous circumstances.

To solve the output-failure replay problem \textsf{ODR} focuses on output determinism -- that is the output of the replay will match the output of the original executable. So reads and writes of shared variables can happen in a different interleaved order than in the original execution but their final values, or output, must be the same as at the end of the original program execution.

By relaxing its record model and focusing on output-determinism \textsf{ODR} provides a low-overhead recording system. Its main downside, however, is that it does not provide full deterministic replay for multiprocessor software systems, since it instead focused only on output-determinism. In all, \textsf{ODR} offers a unique and interesting new approach to providing a record/replay feature that incurs a minimal overhead.

\section{Function Interception Techniques}

Function interception can be used to intercept calls to functions at runtime and either interpose a different function in place of the one called or modify the behaviour of the original function. This project uses function interception to provide deterministic replay at runtime \cite{FunInt}.

Below, I go over some different techniques for intercepting function calls on a variety of platforms and evaluate their suitability for this project.

\subsection{Function Interposition in Linux}

In Linux, function interception can be achieved at runtime by using shared libraries and the LD\_PRELOAD variable.

\subsection{Detouring in Windows}

Function detouring intercepts function calls and re-write target functions at run-time. Detours \cite{detours} is a library for instrumenting Win32 functions dynamically at runtime. A function is intercepted and an unconditional call is inserted in its instructions to call the new function. A pointer to the original function is preserved via trampolining. 

Detouring is useful because they can be used on pre-compiled existing programs and are incredibly fast in their intercepting. I have not used the detouring technique, however, for this project as the Linux kernel provides the LD\_PRELOAD environment variable to intercept shared library calls at runtime.

Detouring is more focused towards extending existing binary software and adding additional functionality to such software. For the purposes of this project, however, simple function interception has proved adequate.

\subsection{Trampolining}

Function trampolining in C and C++ is typically moving from one code path to another. For example, in a C program you might want to call a C++ function. To do this, one might use trampolining by setting up the callback so that the C calling conventions will be converted into the C++ calling convention and allow the C++ method to be called.

Other uses for trampolining include, writing interrupt handlers in C rather Assembly by writing a short trampoline to convert the Assembly calling convention into the C calling convention. 

Function trampolining is particularly suited to this project but the main problem is using binary instrumentation to instrument the original executable and inserting the relevant ``trampoline." For this project it has been simple to use basic dynamic function interception as described above.



\chapter{Approach}
In my approach to creating the tool, I identified three key areas which needed to be resolved before implementation of the tool. These were: thread scheduling, the wrap() function, and the step\_and\_notify() function.


\section{Thread Scheduling}
\section{Wait}
\section{Step and Notify}



\chapter{Development}

\section{Wrapper Library}
The wrapper class. What was the purpose of creating a wrapper class etc.?
\subsection{Problems}

\section{Function Interposition}
Function intercepting and dynamic interception. 
\subsection{Recursive Function Calls}
\subsection{Static Interception}
\subsubsection{Problems}
In this section I will also discuss the many difficulties which I encountered along the way and how I overcame these difficulties and the way in which they effected the course of the project. LD\_PRELOAD is operating system wide etc.
\subsection{Dynamic Interception}
\subsubsection{Problems}
In this section I will also discuss the many difficulties which I encountered along the way and how I overcame these difficulties and the way in which they effected the course of the project. LD\_PRELOAD is operating system wide etc.
\subsection{Pthreads API}
\subsubsection{pthread\_create()}
\subsubsection{pthread\_join()}
\subsubsection{pthread\_mutex\_lock() and pthread\_mutex\_unlock()}
\subsubsection{pthread\_cond\_wait() and pthread\_cond\_broadcast()}
The problem when implementing dysym with pthre cond wait. as described in the link I have emailed myself.





\chapter{Testing and Evaluation}

What tests to run to show the effectiveness of the tool.

\section{Testing Method}

\section{KLEE-THREADS Tests}
In this section I will show the tool working with KLEE-THREADS. That is taking schedules from Paul's tool and then showing that my tool follows these schedules. 

\section{Stability Tests}
I can show the stability of the tool by using my own simple tests and running the tool 1000's of times over these simple programs to show that the tool will force a certain schedule to be followed and prove that it works every time.

Will also use the same tests that Paul used in his MSc. thesis to show that the tool can link up with KLEETHREADS as it is meant to. These are: pbzip, ThreadSanitizer Test Suite and ESBMC Test Suite.

I can also test pigz but this is a similar tool to pbzip2 so this might not be worth it.


\section{Efficiency Tests}

\subsection{Speed Tests}
Use programs that are known to have been speeded up by using pthreads and then test these programs with my tool and compare the speeds to show the minimal overhead that is incurred when using the tool.




Run tests to show that the tool works under lots of different conditions. For example I can test the maximum length of a schedule, run tivial tests thousands of times to show that they same result is obtained, I can also run test with sleeps injected at arbitrary points in the code to show the tool still works.

\section{Portability}

\section{Overall Problems}
How the problems I encountered effected the course of the project.


\section{Overall Evaluation}
Overall evaluation of the tool, how it compares with other similar tools etc.


\chapter{Conclusion}
\section{Achievements}
\section{Future Work}
The most obvious extension to the tool is to continue implementing the rest of the Pthreads API. While it is a large API, I think implementing the whole API is feasible and would result in a robust and reliable tool that could be used with all concurrent C programs that use the Pthreads API to provide deterministic replay. In combination with KLEETHREADS, this would a create a full record/replay suite to concurrenct C programs and would prove an invaluable tool to developers developing concurrent software in C.




\bibliography{mybib}{}
\bibliographystyle{nar}
\end{document}