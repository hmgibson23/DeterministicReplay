\documentclass[11pt,a4paper]{report}
\usepackage[left=2.5cm,right=2cm,top=2cm,bottom=2cm]{geometry}
\usepackage[pdftex]{graphicx}

%\usepackage[nottoc,numbib]{tocbibind}
\usepackage{listings}
\usepackage{cite}
\usepackage{tocloft}
\usepackage{parskip}
\usepackage{float}
\usepackage[nottoc,numbib]{tocbibind}


%Preset style for all code listings is C
\lstset{
captionpos=b,
	language = C,
  basicstyle=\footnotesize,           % the size of the fonts that are used for the code
  numbers=left,                   % where to put the line-numbers
  stepnumber=1,                   % the step between two line-numbers. wef it's 1, each line                                   % will be numbered
  numbersep=5pt,                  % how far the line-numbers are from the code                 % show tabs within strings adding particular underscores
  frame=shadowbox,                   % adds a frame around the code                    % sets default tabsize to 2 spaces
  captionpos=b,                   % sets the caption-position to bottom
  breaklines=true,                % sets automatic line breaking
      % sets if automatic breaks should only happen at whitespace
      showstringspaces=false 	
               extendedchars=true,         %
         breaklines=true,
         basicstyle=\ttfamily
}




\lstloadlanguages{
         C,
         Python
 }


\setcounter{tocdepth}{3}
\addtocontents{toc}{\protect\vspace{10pt}}
\renewcommand{\cftsecleader}{\cftdotfill{\cftdotsep}}
\setlength{\parindent}{0cm}

\begin{document}
\input{./titlepage.tex}




\section*{Abstract}
With the onset of multi-core processors, writing software that takes advantage of such processors has become an essential part of modern software development. Unfortunately, writing concurrent programs is a difficult task and often produces many bugs which will not be found even after extensive testing. There are many scenarios, such as data races and deadlocks that will go unnoticed until a system has gone to production, potentially leading to catastrophic results. To overcome this, many tools that trace concurrent execution have been created to debug concurrent software.

An existing tool KLEETHREADS uses symbolic execution to trace concurrency bugs and outputs a thread schedule to show the conditions for a given bug to arise.

Concurrency bugs are notoriously difficult to reproduce, since many bugs are dependent on a particular thread schedule that occurs only very rarely. The aim of this project has been to provide deterministic replay to concurrent C programs.

<<<<<<< .mine
We introduce a tool, P-Rep,  takes a schedule generated by KLEE-THREADS or a hand-written schedule and forces that thread schedule to be followed. KLEE-THREADS achieves its schedule via symbolic execution. This tool provides a replay feature via function interposition. 
=======
This tool takes a schedule generated by KLEETHREADS or a hand-written schedule and forces that thread schedule to be followed. KLEETHREADS achieves its schedule via symbolic execution. This tool provides a replay feature via function interposition. 
>>>>>>> .r48

P-Rep works with the original Pthreads API and requires no extra-intervention on the part of the programmer. It incurs a minimal overhead and will follow any generated schedule accurately.

The Pthreads API is very large. As a result of this, we have been unable to implement a replay feature for the whole library. Instead, we have focused on four key aspects on the API: thread creation, thread termination, mutex locking and unlocking, and condition waiting. We have made a higly robust deterministic replay tool for these parts of the Pthreads API.

<<<<<<< .mine
We have implemented the final tool by using function interposition. P-Rep will load our shared library and execute a program that uses Pthreads while forcing the thread schedule it has been passed to be followed. It operates in FOUR modes. In its first mode, P-RepP-Rep will force the schedule and either hang or finish execUtion at the end of the schedule. In its second mode, P-Rep will follow the schedule to its end and then stop execution. In its third mode, P-Rep will follow the schedule until its end and then resume normal execution with no further intervention. In its fourth mode, P-Rep will provide a record feature and record the thread schedule of the last execution. 
=======
We have implemented the final tool by using function interposition. The tool will load our shared library and execute a program that uses Pthreads while forcing the thread schedule it has been passed to be followed. It operates in four modes. In its first mode, the tool will force the schedule and either hang or finish execution at the end of the schedule. In its second mode, the tool will follow the schedule to its end and then stop execution. In its third mode, the tool will follow the schedule until its end and then resume normal execution with no further intervention. In its fourth mode, the tool will provide a  detect and record feature. It will detect a deadlock and output the schedule that was followed to reach that deadlock. 
>>>>>>> .r48

\newpage

\section*{Acknowledgements}

I would like to thank my supervisor Alastair Donaldson for his continued support and advice. I would also like to thank Paul Thomson for his creation: KLEETHREADS.

\newpage


\tableofcontents

\newpage
\clearpage
\lstlistoflistings
\clearpage
\listoftables
\chapter{Introduction}

Multi-core processors have moved from specialist computers and large-scale clusters to desktop and laptop computers and are becoming the norm in all areas of computing. The need to make use of multiple processors in software development has become essential and this has led to many new types of bugs emerging.

\section{Deterministic Replay}

The aim of this project has been to create a tool that provides deterministic replay to concurrent software written using the Pthreads API. Deterministic replay is used  to force a program to follow a certain path of execution. By reproducing a particular execution trace, a programmer is able to see an error that might not occur under normal conditions. Many bugs in concurrent software rely on a very specific thread schedule before they will occur. As a result of this, many such bugs will not appear even after thousands of executions. Deterministic replay will force a particular schedule to be followed and reproduce the circumstances that gave rise to the bug, thus allowing the programmer to quickly and accurately debug their software.

<<<<<<< .mine
For deterministic replay to be successful, a thread schedule must be captured from a given program. Once the thread schedule has been captured, deterministic replay becomes possible by forcing the schedule to be followed. P-Rep presented in this paper uses an existing replay tool KLEETHREADS for detecting concurrency bugs in concurrent C programs that use the Pthreads API. P-Rep that is being presented takes a schedule from KLEETHREADS and then follows the path of execution as determined by the passed schedule.
=======
For deterministic replay to be successful, a thread schedule must be captured from a given program. Once the thread schedule has been captured, deterministic replay becomes possible by forcing the schedule to be followed. The tool presented in this paper uses an existing replay tool, KLEETHREADS for detecting concurrency bugs in concurrent C programs that use the Pthreads API. The tool that is being presented takes a schedule from KLEETHREADS and then follows the path of execution as determined by the passed schedule.
>>>>>>> .r48

The Pthreads API is a particularly large API and as a result of its size, we have not been able to implement deterministic replay for the whole API. Instead, we have focused on creating a robust tool to work with thread creation, thread joining, mutex locking and unlocking, and waiting on conditions.


\section{Motivation}
Software bugs remain a major source of annoyance for software developers and with the advent of multi-core processors and the need to write concurrent software. New, more devastating bugs have arisen. These bugs are often difficult to track down and occur only under very specific conditions which might not arise even after extensive testing. To ease the tracing of such bugs, many tools which provide execution traces by a number of techniques have been created.

One such tool KLEETHREADS, uses dynamic symbolic execution to trace concurrency bugs in  concurrent C programs. While KLEETHREADS has proved excellent in tracing bugs, it does not support a replay feature to show programmers the bugs which it traces. The motivation behind this project has been to provide such a tool.

The main motivation for creating P-Rep is to add a deterministic replay feature to the KLEETHREADS tool which already provides a bug trace feature to the Pthreads API.

Programmers can often be sceptical about schedules they are shown which lead to bugs \cite{dut}. Tools like \textsf{gdb} and other popular debuggers can often slow down execution and prevent bugs from occurring in the way that they did in the original execution. By adding a deterministic replay feature to the KLEETHREADS tool, we will be able to show programmers the conditions under which their bug arises and demonstrate the exact conditions under which the bug occurred.

By showing a programmer a bug quickly and allowing them to recreate the exact conditions under which the bug occurred, we will be able to speed up the debugging process significantly as through a combination of the schedules output by KLEETHREADS and the deterministic replay provided by this tool, it is simple to detect, trace and fix bugs quickly and efficiently.

It is also desirable to create a replay feature for a program without having to alter the original source code. This way the programmer can simply run P-Rep using their program and feed P-Rep a schedule. P-Rep will then follow this schedule faithfully to reproduce the conditions under which the bug occurred. By requiring no modification of the original executable, a user is able to use P-Rep with ease.

Some deterministic replay tools, however, achieve deterministic execution in non-deterministic programs but incur a large overhead. Ideally, a tool should incur as little overhead as possible. A tool that produces a large time and space overhead can be inconvenient to use and sometime bug traces may be so large that such tools will run out of memory before finishing the execution replay.


\section{Objectives}

The objectives for the project are as follows:

\begin{itemize}
\item
To provide a tool that takes schedules produced by KLEETHREADS and accurately forces the thread schedules to be followed.
\item
<<<<<<< .mine
To create four different modes of execution for P-Rep. One to simply follow a schedule and either hang or terminate execution depending on its current state. Two to follow a schedule either to its end or an arbitrary point and then resume normal execution so that results can be observed from a certain point. Three to follow a schedule to its end and terminate. Four to provide a record feature to show the schedule P-Rep followed.
=======
To create four different modes of execution for the tool. One: to follow a schedule and either hang or terminate execution depending on its current state. Two: to follow a schedule either to its end or an arbitrary point and then resume normal execution so that results can be observed from a certain point. Three: to follow a schedule to its end and terminate. Four: to provide a record feature to show and save the schedule the tool followed.
>>>>>>> .r48
\item
To create P-Rep such that it can be run with the original executables, so that no source-code level modifications are required and such that no re-linking is required.
\item
To create P-Rep while incurring as minimal runtime overhead as possible so that large schedules can be followed with minimal memory footprints.
\end{itemize} 

\section{Contributions}

The contributions for the project have been as follows:

\begin{itemize}
\item
A novel way of using function interception within the Linux kernel to interpose Pthread functions and force thread schedules to be followed.
\item
A deterministic replay tool that can be run with the original executable and the original functions in the Pthreads API.
\item
A deterministic replay tool that incurs a minimal additional overhead by way of function intercepting using the LD\_PRELOAD environment variable.
\end{itemize}

\section{Results}
The results for the project have been promising. P-Rep works successfully with a large number of thread schedules output by the KLEETHREADS tool and successfully executes with minimal overhead on the original executable. P-Rep only requires an executable that uses the Pthread API as well as a thread schedule for it to follow. 

P-Rep does not have to be used exclusively with KLEETHREADS as it will force execution on any schedule it is passed. Thus a user can create their own schedules for P-Rep to follow and observe the output. In this way, P-Rep is truly a deterministic replay tool for C programs and does not rely on any specific record feature to function correctly.

The main limitations of the project have been in the size of the Pthreads API and the amount of time allocated to complete the project as well as some portability issues. As a result of the size of the Pthreads API, we have been unable to integrate P-Rep with every aspect of the API. Instead, we have focused on creating a robust tool for thread creation, thread termination, mutex locking and unlocking, and waiting on and signalling condition variables. 

There have also been some portability limitations with P-Rep. While P-Rep is guaranteed to work with the Linux kernel, the use of pthread\_tryjoin\_np(...) in thread termination calls limits its portabiliy across other POSIX compliant platforms.


Below is a list of the Pthread functions we have implemented:

\input{APITable.tex}

\newpage



\section{Structure of this Report}
The rest of this report is structured as follows: Chapter 2 presents background and related work, as well as some of the inspirations for P-Rep. Chapter 3 discusses the approach that was taken in the creation of P-Rep and the key concepts of the implementation. Chapter 4 discusses the development process and the problems encountered along the way. Chapter 5 discusses the testing process and the evaluation of P-Rep. Finally, Chapter 6 summarizes the document and concludes the achievements made by the project and also discusses possible future work.

\chapter{Background and Related Work}

Tools already exist that provide both record and replay features to concurrent software on a variety of platforms. This chapter introduces some of the existing record/replay tools and examines their effectiveness and how they have influenced the creation of this tool. We also give a brief introduction to different concurrency problems and their typical solutions.

\section{Concurrency}
Concurrency can best be described as two or more things occurring at once, but not necessarily at the same time. It differs from parallelism (although the too are often used interchangeably) since concurrency allows thread interleaving while parallelism generally refers to two or more threads running simultaneously. 

Concurrency has become a major problem for the modern software developer and many programs are expected to have at least a basic level of concurrency support. The time for developers to simply rely on increased CPU performance to speed up their programs has come to an end \cite{Sutter}.

Writing concurrent software produces bugs that would not usually occur in single-threaded applications. The most obvious example of such a bug is a data race. Data races occur when multiple threads of execution alter the value of a variable in shared memory at the same time. The result is indeterminate and in such cases the programmer cannot know what the value of the variable will be ahead of time. Data races can be resolved using simple concurrency techniques such as mutexes but these can require expertise to use properly and in large systems there may be so many data races that it is impossible for a programmer to find them all.

Another bug common in concurrent software is a deadlock. Deadlocks are particularly nasty, since they often occur when a programmer has already taken measures to avoid concurrency bugs such as data races. An obvious path to deadlock is failing to unlock a mutex after obtaining it and forcing other threads to wait on that mutex. 

Concurrency bugs are difficult to reason about and there may be many possible paths of executions that can be followed in a given program state. As a result of this, even after extensive debugging and testing there may still be bugs in a concurrent system that go unnoticed for long periods of time and applications may even ship with undetected concurrency bugs which can lead to serious complications. 

In recent times the need to have sophisticated debugging tools for concurrent software has increased. It is particularly useful to show a programmer their error rather than simply showing the error trace. 

\subsection{Types of Concurrency Bug}

Below are some common concurrency errors that can occur in concurrent software systems.

\subsubsection{Race Conditions}

A race condition occurs when two or more threads attempt to access a shared variable, without first obtaining a mutex lock. The reading or writing of a shared variable or state should be considered a critical section and should thus be mutually exclusive from other threads. In its critical section, a thread should not be interrupted in order to guarantee the integrity of its access to the shared variable.

Data races can come in two forms. A critical data race occurs when the order in which the value of a variable or variables will effect the final outcome of the program. 

A non-critical data race occurs when no matter what order the variables are changed in the final state of the program remains the same.  

Both types of data race can have equally devastating in consequences in application critical environments, such as healthcare \cite{lev}.

\subsubsection{Deadlock}

A deadlock is when two or more competing threads are waiting on each other with neither releasing their held resource, resulting in no progress being made in the system. A common cause of deadlock is a thread failing to unlock a mutex after finishing its critical section. 

The Coffman conditions \cite{Coff} listed below, are the required conditions for a deadlock to occur:
\begin{enumerate}
\item Mutual Exclusion: At least one resource must be non-shareable. Only one process can use the resource at any given instance of time.
\item Hold and Wait or Resource Holding: A process or thread is currently holding at least one resource and requesting additional resources which are being held by other processes.
\item No Preemption: The operating system must not de-allocate resources once they have been allocated; they must be released by the holding process voluntarily.
\item Circular Wait: A process or thread must be waiting for a resource which is being held by another process or thread, which in turn is waiting for the first process or thread to release the resource.
\end{enumerate}


\section{Bug Detection}
 
Some tools which have been created to detect concurrency bugs using a variety of techniques. e give a brief outline and evaluation of each of these tools below.

\subsection{KLEETHREADS}

KLEETHREADS uses dynamic symbolic execution to detect data races in concurrent C programs. It is built on top of the KLEE symbolic virtual machine. KLEE is capable of automatically generating tests that achieve high coverage of complex programs \cite{KLEE}.KLEE uses the LLVM instruction set to map instructions to constraints without approximation and to execute the program within its framework. KLEE uses symbolic execution on a set of generated states to select and execute a wide variety of execution paths. KLEE handles nondeterminism by modelling the native execution environment symbolically \cite{Pt}. This enables KLEE to consider multiple paths under a variety of situations, allowing it to model the non-deterministic state.

After KLEETHREADS has found a bug it will produce a thread schedule that led to the discovered bug and continue its execution to find more bugs. A typical thread schedule that KLEETHREADS produces will instrument the main thread as 0 and instruments each created thread as 1,2,3 etc. An example schedule might look as follows: [0,0,0,1,1,2,2,3,2,2,1], with the end of the schedule leading to a bug. KLEETHREADS will typically output a large number of schedules for any given executable. If a program is particularly large, it is possible to pass KLEE arguments to restrict the amount of schedules produced and also to alter what sort of schedules it produces. For example, we can force KLEETHREADS to output longer schedules that might lead to very specific trace occurring. This can be useful to the user since it allows them to track down specific bugs.

<<<<<<< .mine
KLEE supports symbolic implementation of many POSIX functions so many programs using POSIX-compliant software can run in KLEE without having to recompile or instrument them. This is a nice match P-rep which similarly requires no recompilation or re-linking of executables it is passed.
=======
KLEE supports symbolic implementation of many POSIX functions so many programs using POSIX-compliant software can run in KLEE without having to be recompiled or instrumented. This is a nice match to our tool which similarly requires no recompilation or re-linking of the executables it is passed.
>>>>>>> .r48

Our tool was originally conceived as an extension to KLEETHREADS that would provide deterministic replay using the schedules that KLEETHREADS output. For this reason, the schedules which our tool follows are similar in design to those output by KLEETHREADS â€“ that is, the main is 0 and is thread created is instrumented as 1,2,3 etc. Nevertheless, our tool will work independently of KLEETHREADS but is works excellently with schedules that KLEETHREADS produces.

Being built on top of the KLEE symbolic virtual machine enables KLEETHREADS to have very wide search space and produce many more schedules than typical replay tools. This is a major advantage, given the amount of concurrency bugs it can find in a given program after just one symbolic trace.



\subsection{Helgrind}
Helgrind is a tool provided as part of the Valgrind tool suite for detecting synchronisation errors in C, C++ and Fortran programs that use the Pthreads API. It focuses on three key areas of error detection: misuses of the Pthreads API, potential deadlocks, and data races.

Helgrind works in conjunction with Valgrind so executes a user's program within the Valgrind framework. It intercepts Pthreads function calls to check for misuses of the Pthreads API and reports the errors back to the user. It detects potential deadlocks by monitoring the order in which threads obtain locks and building a graph to represent this ordering. If it detects a cycle in the graph it has built then it will raise a deadlock warning. 

In order to detect data races, Helgrind uses the Eraser algorithm \cite{Savage}. It relies on the happens-before relation \cite{Lamport} to determine the expected ordering of data accesses. If, through its monitoring of variable accesses, Helgrind detects that the accesses are ordered by the happens-before relation then nothing is raised. If the accesses are not ordered by the happens-before relations, however, then Helgrind will signal a data race detection. The happens-before relation only provides partial ordering not total ordering -- that is that two variables are merely unordered with respect to each other.

Helgrind's main limitations are that at times it can output both false negatives -- undetected data races -- and false positives -- data races that may not actually be data races.  

\subsection{ThreadSanitizer}

ThreadSanitizer is part of the Google data-race-test tool suite and is a data race detection tool that seeks to eliminate the false negatives and false positives that are output by Helgrind and create a more efficient concurrent bug detection tool. The Linux and Mac versions of P-Rep are based on Valgrind \cite{valgrind} and the Windows version is base on PIN \cite{PIN}.

ThreadSanitizer runs as part of the Valgrind tool suite and uses a hybrid algorithm as well as a pure happens-before mode for efficient data race detection \cite{tsan}. 

ThreadSanitizer's hybrid algorithm works by observing a program's execution as a sequence of events. The key events are memory accesses and synchronisation events. A state machine is also used to maintain the history of its observed events \cite{tsan}. ThreadSanitizer's hybrid algorithm will report more false positives but will also detect more data races.

Since ThreadSanitizer can operate in different modes, different results will be observed from each execution instance. In pure happens-before mode less data races will be detected and the results are less predictable but it will only report false positives if the program is custom-lock free. The advantage of ThreadSaniztier's pure happens-before mode is that ThreadSanitizer will report all locks involved in a race while a classical pure happens-before mode is unaware of locks and thus can't include them in its report\cite{tsan}.

ThreadSanitizer's main advantage is that is uses an existing tool, Valgrind, to provide better bug detection features than Helgrind, as well as being able to be run in multiple modes. When using ThreadSanitizer on our tool to detect a potential data race in the wrapper libary it proved more effective in finding the bug than Helgrind.


\section{Record/Replay Tools}

Record/Replay in concurrent software debuggers is a feature that is provided to record a trace to a bug and then replay the conditions under which the bug occurred with the aim of reproducing the bug.

There are existing tools which provide both a record and replay feature to finding concurrency bugs. Below we list some of these tools and evaluate their advantages and disadvantages. Most of these tools focus on the Java programming language and target the Java Virtual Machine.

\subsection{CHESS}

\textsf{CHESS} introduces the concept of concurrency scenario testing, in which a system designer considers interesting scenarios to test the system under \cite{chess}. In order to replay a given scenario, CHESS uses model checking to systematically generate all interleavings within that scenario. A model checker captures all non-determinism within a system and then attempts to enumerate all of those possible choices. To capture non-determinism, \textsf{CHESS} uses a simple abstraction for each asynchronous execution called a task. Any execution of a task results in a new state condition. To implement this abstraction layer, \textsf{CHESS} provides a  set of wrappers for the Win32 API.

\textsf{CHESS} controls the scheduling of tasks by by intstrumenting all of the functions in the concurrency API of the platform that create tasks and access synchronisation objects. It does this to avoid perturbing the system more than absolutely necessary and in order to prevent performance limitations by having \textsf{CHESS} require its own modified version of the runtime platform. Only one thread is allowed to run at anytime to emulate the test on a single processor machine. The reason for this approach is to prevent threads that are running simultaneously from creating data races that \textsf{CHESS} cannot control.

The main advantage of \textsf{CHESS} is its thoroughness. For each bug found by \textsf{CHESS}, it is able to consistently reproduce the error, therefore making it signiificantly easier to show the error and thus to debug it. By allowing a system designer to test many scenarios, \textsf{CHESS} allows a certain amount of customisability in its debugging and thus increases its ease of use. The fact the \textsf{CHESS} requires no modified runtime platform to execute is also particularly useful as it minimises the overheads produced by using a record/replay tool.  

The main disadvantage of \textsf{CHESS} is that it does not try to reproduce all sources of non-determinism resulting in an incomplete search path. \textsf{CHESS} will only search the passed thread schedule so if a bug depends on a particular series of inputs under certain conditions, it will not be found under a normal execution trace in \textsf{CHESS}. 



\subsection{LEAP}
\textsf{LEAP's} general approach for tracing execution is to force each shared variable to record each thread access during a given execution \cite{Huang}. To achieve this it is required to precisely locate which variables can be considered shared. This is achieved by using a static field-based shared variable scheme to identify which variables are being accessed. 

\textsf{LEAP} relies on a transformer to provide instrumentation to an intermediate representation of Java bytecode. It does this by instrumenting critical areas of the bytecode and inserting calls to the \textsf{LEAP} API so that correct record and replay can be recorded by P-Rep \cite{Huang}.

\textsf{LEAP} handles its record feature by invoking the \textsf{LEAP} API on each critical event it has identified to record the ID of the thread performing the access into the access vector. Once program execution has finished, LEAP will output a replay driver consisting of the thread creation order list and the access vector list \cite{Huang}.

\textsf{LEAP's} replay feature works by associating each thread in the schedule with a semaphore maintained in a global data structure to allow each thread to be suspended and resumed on demand \cite{Huang} rather than having to rely on Java's built in multi-threading tools which would not be suitable for \textsf{LEAP's} replay implementation.

\textsf{LEAP} is successful in that it provides a high-level of concurrent bug reproducibility while incurring a fairly minimal runtime cost. Its main disadvantage, however, is the need to insert instrumented API calls into an intermediary bytecode, since this means it cannot be used with pre-compiled Java programs. Also neither the record part nor the replay part of P-Rep can be used independently, which limits P-Rep's usability.

Our tool takes a similar approach to \textsf{LEAP} in thread scheduling, since it associates all threads with a global pthread condtion variable so that threads can be put to sleep and woken on demand. This approach is advantageous in its simplicity since it requires no intervention with existing source code. 

\subsection{DejaVu}
\textsf{DejaVu} aims to provide a record/replay feature to the Java programming language by identifying a logical thread schedule. Identifying a logical thread shedule aims to make \textsf{DejaVu} more efficient \cite{DejaVu}.

A logical thread schedule consists of one or more thread schedules belonging to the same equivalence class. Schedules can be deemed equivalent if the physical thread schedule matches the ordering of shared variable accesses in a given execution \cite{DejaVu}. The information captured in a logical thread schedule is enough for \textsf{DejaVu} to reproduce the execution behaviour of a program during execution. 

\textsf{DejaVu} is a modified Java Virtual Machine that can provide deterministic replay to multi-threaded Java programs \cite{DejaVu}. This is a desirable feature since it means that the replay can be provided on existing Java bytecode with minimal overhead.

The main advantage of \textsf{DejaVu} is that it can be used with programs written in Java with no need for recompilation. The main disadvantage is that users wishing to \textsf{DejaVu} must use the virtual machine provided to debug their programs. 

\section{Other Approaches}

\subsection{Output Deterministic Replay}
\textsf{Output Deterministic Replay (ODR)} is a software only tool that targets a variety of software and provides a minimal overhead in its replay execution. It is written in C and x86-Assembler and aims to be a lightweight middleware for Linux programs \cite{ODR}.  

The main difference between \textsf{ODR} and other replay tools is its approach to replication of the original file. \textsf{ODR} provides only a low-fidelity replay system, rather than the structured deterministic approach other tools provide \cite{ODR}.

The \textit{output-failure replay problem} is to ensure that any failures which occur in the original run of a program are visible in the replay of the program \cite{ODR}. This is a different approach to deterministic replay since it provides guarantees about the final program state rather than the execution path, allowing multiple paths to be explored in a given replay provided they lead to the same output. This can expose bugs that might occur under numerous circumstances.

To solve the output-failure replay problem \textsf{ODR} focuses on output determinism -- that is the output of the replay will match the output of the original executable. So reads and writes of shared variables can happen in a different interleaved order than in the original execution but their final values, or output, must be the same as at the end of the original program execution.

By relaxing its record model and focusing on output-determinism \textsf{ODR} provides a low-overhead recording system. Its main downside, however, is that it does not provide full deterministic replay for multiprocessor software systems, since it instead focuses only on output-determinism. In all, \textsf{ODR} offers a unique and interesting new approach to providing a record/replay feature that incurs a minimal overhead.

\textsf{ODR's} approach, however, is not suitable with out tool. As the aim of the creation of this tool was to provide accurate replay of a given execution trace, simply guaranteeing that the final output will be the same as in the original execution is not enough to provide formal deterministic replay for concurrent C programs, as KLEETHREADS will output a schedule as far as a bug, thus resulting in schedules that are smaller than a full program execution which means there is no guarantee of the final output of the program's execution.

\section{Function Interception Techniques}

Function interception can be used to intercept calls to functions at runtime and either interpose a different function in place of the one called or modify the behaviour of the original function. This project uses function interception to provide deterministic replay at runtime \cite{FunInt}.

Below, we go over some different techniques for intercepting function calls on a variety of platforms and evaluate their suitability for this project.

\subsection{Function Interposition in Linux}

In Linux, function interception can be achieved at runtime by using shared libraries and the LD\_PRELOAD variable. A user can specify a .so file as the file to be used first for looking up shared objects. Thus, at runtime, each call to libraries will first be looked up in the library specified in the LD\_PRELOAD. If the call is found, then the version in the .so provided will be used. If there is no matching function call then the system will look for the function elsewhere.

This technique is particularly useful for this project as it can be done in Linux with no recompiling or relinking of binaries so we can use function interception to load a different library than the one called in their executable and observe different results. 

Functions provided by the dlfcn.h also make it simple to interpose function calls at runtime with functions provided in the .so file that is set in the LD\_PRELOAD variable. This project has made extensive use of the dlsym() function in particular. The dlsym(void *restrict handle, const char *restrict name) function returns a handle to the next object with the same name as specified in the name parameter. This handle can then be used to call the function named. This is expecially useful as it is possible to maintain the original functionality of the overridden function through this pointer.
  

\subsection{Detouring in Windows}

Function detouring intercepts function calls and re-writes target functions at run-time. Detours \cite{detours} is a library for instrumenting Win32 functions dynamically at runtime. A function is intercepted and an unconditional call is inserted in its instructions to call the new function. A pointer to the original function is preserved via trampolining. 

Detouring is useful because it can be used on pre-compiled existing programs and are incredibly fast in their interception. 

We have not used the detouring technique, however, for this project as the Linux kernel provides the LD\_PRELOAD environment variable to intercept shared library calls at runtime.

Detouring is more focused towards extending existing binary software and adding additional functionality to such software. For the purposes of this project, however, simple function interception has proved adequate.

\subsection{Trampolining}

Function trampolining in C and C++ is typically moving from one code path to another. For example, in a C program you might want to call a C++ function. To do this, one might use trampolining by setting up the callback so that the C calling conventions will be converted into the C++ calling convention and allow the C++ method to be called.

Other uses for trampolining include writing interrupt handlers in C rather Assembly by writing a short trampoline to convert the Assembly calling convention into the C calling convention. 

Function trampolining is particularly suited to this project but the main problem is using binary instrumentation to instrument the original executable and inserting the relevant ``trampoline." For this project it has been simple to use basic dynamic function interception as described above.



\chapter{Approach}
<<<<<<< .mine
In our approach to creating P-Rep, we identified three key areas which needed to be resolved before implementation of P-Rep. These were: thread scheduling, the wrap() function, and the step\_and\_notify() function. In addition to these some consideration into the two modes of execution needed to be taken into account. 
=======
In our approach to creating the tool, we identified three key areas which needed to be considered before implementation of the tool. These were: thread scheduling, the wrap() function, and the step\_and\_notify() function. In addition to these, some consideration into the different modes of execution needed to be taken into account. 
>>>>>>> .r48

<<<<<<< .mine
In its current state P-Rep will run in four modes of execution as specified by a command line flag. In the first mode, P-Rep will simply follow the schedule to its end and either hang or continue execution dependent on the schedule length. In the second mode of execution, P-Rep will follow the schedule to its end and then terminate.  In the third mode of execution, P-Rep will force the schedule to be followed to its end but then will continue normal execution. In its fourth mode of execution, P-Rep will run in record mode and will try to record the thread schedule it followed in a given execution. All of these modes are discussed further below.
=======
In its current state the tool will run in four modes of execution as specified by a command line flag. In the first mode, the tool will simply follow the schedule to its end and either hang or continue execution dependent on the schedule length. In the second mode of execution, the tool will follow the schedule to its end and then terminate.  In the third mode of execution, the tool will force the schedule to be followed to its end but then will continue normal execution. In its fourth mode of execution, the tool will run in record mode and will try to detect a deadlock and record the thread schedule it followed in to get to that deadlock. All of these modes are discussed further below.
>>>>>>> .r48


\section{Thread Scheduling}

In order to guarantee a particular thread schedule is followed, it is necessary to provide a thread scheduler to determine which threads should be run next. The role of the thread scheduler should be to put threads to sleep and wake them up on demand and explicitly specifiy which thread is eligible to be run.

This tool approaches thread scheduling in a simple manner. When threads are created they are assigned an instrumented ID which is matched with their pthread ID and placed into a C++ STL map container. Each time a synchronisation point occurs, a thread must call the wait() function in order to check if it is eligible to be run. If a thread's ID does not match the current ID shown in the schedule then it will be required to wait on a global pthread condition variable.

So that threads are not indefinitely put to sleep an additional function, step\_and\_notify, is used to move the schedule along to its next step and to broadcast to all of the sleeping threads so that they can check if they are eligible to be run.

<<<<<<< .mine
The main limitation to this approach is that specific threads cannot be run on demand, since the broadcast will wake all waiting threads rather than one single thread. For example, if threads with instrumented IDs: 1,2,3 are all waiting on the global condition and we wished to wake thread 2 only, this would not be possible in the current implementation of P-Rep. This loss of fine-grained control, however, is made up for by the accurate following of a specific schedule that P-Rep allows. P-Rep will follow the schedule it has been passed faithfully. To observe different behaviour, or to choose a different thread to be run at a certain time, it is enough to simply pass a new schedule to P-Rep. Having to maintain prior knowledge of the schedule and which thread to wak next would incure a significant overhead. Using a broadcast wakes all the threads, which will then read the schedule and only run if they are eligible to be run.
=======
The main limitation to this approach is that specific threads cannot be run on demand, since the broadcast will wake all waiting threads rather than one single thread. For example, if threads with instrumented IDs: 1,2,3 are all waiting on the global condition and we wished to wake thread 2 only, this would not be possible in the current implementation of the tool. This loss of fine-grained control, however, is made up for by the accurate following of a specific schedule that the tool allows. The tool will follow the schedule it has been passed faithfully. To observe different behaviour, or to choose a different thread to be run at a certain time, it is enough to simply pass a new schedule to the tool. Having to maintain prior knowledge of the schedule and which thread to wake next would incure a significant overhead. Using a broadcast wakes all the threads, which will then read the schedule and only run if they are eligible to be run.
>>>>>>> .r48

Since P-Rep will follow any schedule it is passed, a user can specify a schedule for it to follow to observe the results. This is particularly useful for scenario checking, since a system designer can write a specific schedule to lead to a certain scenario and then observe the behaviour. In this way, P-Rep can be used independently of KLEETHREADS.

Some thread schedules are simply infeasible. For example, if the passed schedule is handmade, there might be syncrhonisation point that the schedule write does not consider, therefore resulting in schedule which simply cannot be follow with the tool. In this case, the tool will hang or raise an exception and terminate stating that the schedule it has been passed in invalid. If no schedule is specified, the tool will run in record mode.

\section{Wait}
The wait() function is crucial to ensuring that threads wait until they are eligible to be run. It is implemented by using a global pthread\_cond\_t condition variable to force all threads to wait on the schedule. By taking this approach, threads can be effectively put to sleep and woken up on demand. 

A thread will be required to call the wait() function at each synchronisation point, so that correct synchronisation of all active threads can be achieved. Once a thread has entered a wait state, it will wait until its instrumented ID matches the current ID in the schedule. This approach means that only the scheduled thread will be allowed to run next and all other threads will be required to wait and in this way threads can be put to sleep and woken up on demand each time they call a function that requires synchronisation. 

We also make use of the original Pthreads API, specifically the Pthread condition functions which means no source code instrumentation is required.


Below is the source code for the wait() function:

\lstinputlisting[float=h!,caption=The wait function]{wait.c}



\section{Step and Notify}
The step\_and\_notfiy() function is used to increment the current schedule step and to wake threads which are currently sleeping in the wait() function. Step is a global variable used to monitor the progress of the excutable and to index the schedule. Each time a thread enters and leaves a synchronisation function a call to step\_and\_notify() is made. The call wakes other threads so that if the callee is not eligible to be run, the scheduled thread can begin execution. Each call to the step\_and\_notify() increments the global step variable and moves the schedule along.

Like the wait() function, step\_and\_notify() makes use of an existing Pthread API function -- specifically pthread\_cond\_broadcast(). The function must call this to ensure that threads waiting in the wait() function are woken so that the schedule can be checked and the eligible thread can be run. P-Rep has no current implementation to intercept the pthread\_cond\_broadcast() function so there is no need to call it through a handle returned by dlsym() and the original API function can be used without issue.

To ensure the safe protection of the global step variable, each thread that enters step\_and\_notify() must lock a mutex before performing any write access of the step variable. Without this measure, it would be impossible to follow a schedule in its entirety without getting skewed values for step.

\vspace*{0.3em}

Below is the source code for the step\_and\_notify() function:

\lstinputlisting[float=h!,caption=The step\_and\_notify function]{stepandnotify.c}

\section{Modes of Execution}

When approaching the development of P-Rep, it seemed most appropriate to offer four modes of execution so that users could specify the results they might want to observe 

\subsection{Default Execution Mode}

In its standard mode of execution, P-Rep will follow a schedule to its end and then either hang or terminate depending on the length and values within the schedule. Used in conjunction with KLEETHREADS, in this mode P-Rep will simply cease execution and hang at the end of the schedule. The purpose of this execution mode is to show the user their bug occurring under the very specific conditions that it might occur in the first place. 

As an example execution run, consider the following:
\begin{itemize}
\item P-Rep is fed the following schedule which leads to a data race: {0,0,0,1,1,2}.
\item P-Rep will run thread 0 three times and then switch to thread 1.
\item Thread 1 will be executed twice before thread 2 is executed.
\item At this point P-Rep will hang.
\end{itemize}

<<<<<<< .mine
In this example, the exact conditions under which the data race occurred have been reproduce by P-Rep. Thus, a programmer can observe the output of the thread schedule being followed and recreate the conditions under which the data race occurred. It is important to note that in a data race scenario as described above, P-Rep will hang as a result of the schedule end being reached not as result of a data race occurring. 
=======
In this example, the exact conditions under which the data race occurred have been reproduce by the tool. Thus, a programmer can observe the output of the thread schedule being followed and recreate the conditions under which the data race occurred. It is important to note that in a data race scenario as described above, the tool will hang as a result of the schedule end being reached not as result of a data race or deadlock occurring. The tool has reached the end of the schedule but threads still look at the schedule at each synchronization point. Since the thread numbers are no longer valid now that we are at the end of the schedule, no further progress is made as no threads are eligible to be run. 
>>>>>>> .r48

\subsection{FOLLOW\_AND\_TERMINATE}

In this mode of execution P-Rep will follow a schedule until its end and then terminate. The aim is to show a user the first bug and reproduce the conditions under which the bug arose. 

It is important to note that in this mode P-Rep will only terminate if the schedule has led to a concurrency bug which will allow termination. 

For example, a schedule that leads to a deadlock will be followed to that deadlock and then deadlock. This is because the checking for the end of the schedule is not pre-empted and the program will only execute once the end of the schedule has been reached and if a schedule leads to a deadlock then this deadlock will occur.

<<<<<<< .mine
To achieve this follow and terminate technique. The script that starts P-Rep sets an environment variable which is read by the .so library at the start of the program. If the FOLLOW\_AND\_TERMINATE environment variable has been set then this flag will be raised and each time the wait() function is invoked, P-Rep will check whether or not the end of the schedule has been reached. If it has then the program will execute. The downside to this approach occurs in the checking of global step to determine if the schedule has come to an end, since multiple threads will call wait() at the same time thus creating a reader's/writer's problem. This is trivial to solve using mutexes, however, and maintains the minimal overhead the program incurs.
=======
To achieve this follow and terminate technique. The script that starts the tool sets an environment variable which is read by the .so library at the start of the program. If the FOLLOW\_AND\_TERMINATE environment variable has been set then this flag will be raised and each time the wait() function is invoked, the tool will check whether or not the end of the schedule has been reached. If it has then the program will terminate. The downside to this approach occurs in the checking of global step to determine if the schedule has come to an end, since multiple threads will call wait() at the same time, thus creating a readers/writers problem. This is trivial to solve using mutexes, however, and maintains the minimal overhead the program incurs.
>>>>>>> .r48

\subsection{FOLLOW\_TO\_END}

When running in this execution mode, P-Rep will follow the schedule it is passed until its end and then resume normal execution. This allows a particular path through a program's execution to be followed and then the remaining execution of that program to be observed. 

The user's program will not, however, be executing the original Pthreads functions that have been intercepted by P-Rep. This is because once the LD\_PRELOAD variable has been set the loader will only look in the location set in the environment variable for shared library objects. Thus all calls to Pthread functions supported by P-Rep will still be intercepted until the program has finished its execution. To overcome this limitation, the script that launches P-Rep will set an environment variable FOLLOW\_TO\_END which will be checked by P-Rep on the first call to pthread\_create(). P-Rep will set the relevant flag and once the end of the schedule has been reached, all further calls to intercepted Pthread functions will skip the wait() and step\_and\_notify() functions and instead simply call the orignal API functions through the handles returned by calls to dlsym(). 

The function which determines if we have reached the end of the schedule and can resume normal execution is shown below:

\lstinputlisting[caption=no\_follow() function] {nofollow.c}

This approach means that the original executable can continue to run as normal, while incurring a minimal overhead in its call to the intercepted functions.

One problem we encountered when implementing this mode was determining if threads should call the normal versions of the Pthreads API functions or the overridden one. There were several cases in which we found that after the no\_follow() function was returning true, threads which had been running in parallel were already being executed with the overridden function because they had already progressed past the points which determined which function to call.

As an example of this problem consider the small code snippet below:

\lstinputlisting[caption=Mutex locking when FOLLOW\_TO\_END set]{badendmutex.c}

Consider two threads: A and B.

In this example, we can see that it might be possible for thread A to enter the pthread\_mutex\_lock function before the end of the schedule has been reached so it will enter the overridden branch of the code and call pthread\_trylock. While it is in this branch, thread B could cause the end of the schedule to be reached and the no\_follow function would start returning 1. Thus thread A would be calling pthread\_trylock rather than the original pthread\_mutex\_lock and so not executing as normal. In the case that there was a locked mutex that thread B was trying to obtain, B would exit this function normally as if it had obtained the mutex. This would of course, avoid any deadlocks or data races that might occur at the end of a particular schedule.

To fix this problem, we inserted calls to no\_follow() before returning from our overridden function calls, so that in an event similar to above, the original pthread functions would still be called. While this added a small extra overhead to the calls to the overridden functions, it elminated the possibility that threads would still be calling our overridden function when they were meant to be calling the normal functions.

\subsection{RECORD Mode}

P-Rep's record mode's purpose is to detect a given deadlock and then output the schedule that was followed leading to this deadlock. 

<<<<<<< .mine
In order to build a schedule independent of P-Rep's execution mode, we inserted a call to a C++ function that dynamically builds a schedule with each call to step\_and\_notify(). Since step\_and\_notify() is called as every synchronisation point, we were able to trace the order in which threads were executing in any given execution. After the monitor thread detects a deadlock, it will output the schedule P-Rep followed to a file so that this file can then be fed to P-Rep and the execution replayed.
=======
In order to build a schedule independent of the tool's execution mode, we inserted a call to a C++ function that dynamically builds a schedule with each call to step\_and\_notify(). Since step\_and\_notify() is called at every synchronisation point, we were able to trace the order in which threads were executing in any given execution. After the monitor thread detects a deadlock, it will output the schedule the tool followed to a file so that this file can then be fed to the tool and the execution replayed.
>>>>>>> .r48

P-Rep's minimalist replay mode was implemented using a simple monitor thread. On the first call to pthread\_create() in any program, P-Rep will create and initialise a thread to monitor the progress of thread execution. The monitor thread's aim is to check for satisfactory progress and, if satisfactory progress has not been made, to terminate program execution and print the schedule that P-Rep followed to reach the deadlocked state. 

My initial approach to the monitor thread is shown below:

\lstinputlisting[caption=Initial Monitor Thread]{monitorbad.c}


The problem with this initial approach is that it will only check for deadlocks if P-Rep is passed an initial schedule. The other issue with this implementation is that the comparison between last\_step and the global step is almost redundant, since we would assume that the step and last\_step are being continuously updated, therefore they will never be equal, so this comparison is rather pointless. To create a better monitor thread it was necessary to determine if the global step variable was still being incremented. 

We did this in the approach shown below:

\lstinputlisting[caption=Modified Monitor Thread]{monitorgood.c}

As you can see this monitor will work independently of a schedule and will work with P-Rep if no schedule is passed, since the global step is incremented each time step\_and\_notify is called and P-Rep builds the followed schedule each time step\_and\_notify is called.

<<<<<<< .mine
The record mode can in fact be used to trace any execution that might lead to a deadlock in a concurrent C program. This is in keeping with P-Rep's independence, since it means that a user can obtain a trace of any execution should they wish to.

=======
The record mode can in fact be used to trace any execution that might lead to a deadlock in a concurrent C program. This is in keeping with the tool's independence, since it means that a user can obtain a trace of any execution that causes a deadlock should they wish to.
\clearpage
>>>>>>> .r48
\subsection{Modified wait()} 

The modified version of the wait() function to account for the different execution modes is shown below:

\lstinputlisting[caption=The modified wait function]{fullwait.c}










\chapter{Development}

<<<<<<< .mine
Below we detail the development process we went to create P-Rep. We explain, in detail, how we implemented each overriden function and discuss the problems and their resolutions to each overridden function.
=======
Below we detail the development process we underwent to create the tool. We explain, in detail, how we implemented each overriden function and discuss the problems we encountered and their resolutions.
>>>>>>> .r48

\section{Thread ID creation and Assignment}

When a thread is created using pthread\_create() an ID is assigned to the pthread. This ID is usually a hexadecimal number that is determined by the operating system. Since KLEETHREADS aims to work with any concurrent C program and it cannot know ahead of time what thread ID the operating system will assign to threads, it outputs its schedules with thread IDs starting at 0. An example output might be (0,1,2,3). Thread 0 will always represent the main thread and each thread from then on will be assigned an ID. 

Since P-Rep receives a schedule in this format, it was necessary to add instrumented IDs to the threads as they were created so that a schedule could be followed without any modification. 

To achieve this, each time a thread is about to be run its  instrumented ID along with its pthread ID is inserted into a C++ STL map which holds a mapping of instrumented IDs to pthread IDs. Each time a thread enters a section in which its ID is required to continue, a call to pthread\_self() is made to obtain the pthread ID. This pthread ID can then be used to index the map and obtain the instrumented ID of the calling thread. Since code marked with ``extern C" will prevent the C++ compiler from mangling the names, a C program is able to call the C++ functions as if they were C functions. Doing this, enabled us to use C++ libraries and tools with the libraries written in C. 

An example Thread Map might look as follows:

\input{SampleMap.tex}

Using an STL map enables fast look-up of thread IDs and also means that nothing needs to be passed to the wait() and step\_and\_notfiy() functions to verify the thread being called. 

Two functions achieve the above functionality. The first  put\_instrumented\_id(pthread\_t p, int current\_id) will create a mapping between the pthread\_t p and the current\_id. In this case, current\_id is a global variable, incremented on each call to pthread\_create() to hold the ID of the next thread to be created. To prevent data races,  a thread must lock the global current\_id before incrementing it.

The second function get\_instrumented\_id(pthread\_t p) will look up and return the instrumented ID of the pthread p in the STL map defined in the thread\_map.cpp file. The returned ID can then be used by P-Rep to check the schedule and determine if the calling thread is eligible to be run.

Below is the source code for the Thread Map:
\vspace{1em}
\lstinputlisting[caption=The Thread Map]{thread_map.cpp}


\section{Wrapper Library}

<<<<<<< .mine
Before implementing P-Rep using function intercepting, we decided to write a wrapper class to use with our own Pthread programs. The purpose of creating such a wrapper was to come to terms with the Pthreads API but also to make sure that the key parts of P-Rep functioned in this environment first before moving on to the more complex function interception techniques. 
=======
Before implementing the tool using function intercepting, we decided to write a wrapper library to use with our own Pthread programs. The purpose of creating such a wrapper was to come to terms with the Pthreads API but also to make sure that the key parts of the tool functioned in this environment first before moving on to the more complex function interception techniques. 
>>>>>>> .r48

This part of the development process was purely for experimental purposes and to understand the processes involved in designing P-Rep. The obvious downside to using the wrapper library exclusively would have been the need for the program to be recompiled with the wrapper library included and the program to explicitly call the overridden functions.

To help with reasoning about how schedules should be followed, we wrote programs in which several threads accessed and altered a global variable without attempting to lock a mutex. The aim here was to write schedules that would induce a particular value for the global variable at the end of the program's execution. 

In the following program:

\lstinputlisting[caption=Forcing a schedule]{induce.c}

<<<<<<< .mine
The schedule: (0,0,0,0,0,1,3,4,2,0,0,0,0,0) will guarantee that the final value of GLOB will be 3. A minor change to this schedule will force the GLOB to be 1,2, or 3. The purpose of this exercise was to ensure that P-Rep could faithfully follow certain schedules and enforce a particular value for the global variable at the end. This was then trasnferable to the version of P-Rep which used function intercepting and passing it the same schedule would yield the exact same results.
=======
The schedule: (0,0,0,0,0,1,3,4,2,0,0,0,0,0) will guarantee that the final value of GLOB will be 3. A minor change to this schedule will force the GLOB to be 1,2, or 3. The purpose of this exercise was to ensure that the tool could faithfully follow certain schedules and enforce a particular value for the global variable at the end. This was then transferable to the version of the tool which used function intercepting and passing it the same schedule would yield the exact same results.
>>>>>>> .r48

By opting to write a wrapper library to see how P-Rep would work before implementing any dynamic interception, we were able to get to grips with how the threads could be put to sleep and woken on demand and also how thread scheduling should work. Once the wrapper was at a workable state and we were satisfied with the way it handled shcedules, we could then move on to implementing P-Rep via function intercepting.


\subsection{Problems}

The main problem we encountered when implementing the wrapper library was in inserting the correct thread ID into the Thread Map. 

\clearpage
The problem occurred in thread creation. The initial intercept\_pthread\_create looked as follows:
\lstinputlisting[caption=intercept\_pthread\_create]{wrapper.c}

The problem in this implementation occurs in line 25. While a thread is inserting the thread ID into the thread map, it may be that another thread calls intercept\_pthread\_create and thus a data race occurs. Initially this problem was hard to track down. In order to find it, we made use of the ThreadSanitizer tool, which showed us the data race. 

Using an existing concurrency bug detection tool during the development of the wrapper library was particularly useful to the overall progression of the project because it gave us a clear idea of how concurrency bugs can be traced and alerted us to some of the problems implicit in writing any kind of concurrent software. We also ran Helgrind on P-Rep to try and determine the cause of the problem. While both tools found the bug, Helgrind reported more false positives than ThreadSanitizer. 

This bug was easily fixed by placing the call to put\_instrumented\_id in the run\_thread function to guarantee that the calling thread had its ID placed in the Thread Map rather than another thread accessing the map at the same time. As a result of the semantics of STL maps, the keys were kept unique so concurrent writes would not result in existing threads having their IDs overwritten.

The new run\_thread function is shown below:
\lstinputlisting[caption= run\_thread with data race removed]{runrace.c}


After fixing the bug the only race conditions that either tool found were concurrent reads of the Thread Map, which is acceptable since there might be occasions on execution when more than one thread is required to read the thread map to obtain its instrumented ID in order to determine its eligibility to be run.

\section{Function Interposition}

\subsection{Recursive Function Calls}

<<<<<<< .mine
Recursive function calls was one of the main problems we face when implementing function interception. The reason for this was that the library which P-Rep uses to intercept function calls makes heavy use of the existing Pthreads API. For example, when a thread makes a call to lock a mutex, eventually that mutex must be locked, or else execution of the program will become indeterminate. 
=======
Recursive function calls was one of the main problems we faced when implementing function interception. The reason for this was that the library which the tool uses to intercept function calls makes heavy use of the existing Pthreads API. For example, when a thread makes a call to lock a mutex, eventually that mutex must be locked, or else execution of the program will become indeterminate. 
>>>>>>> .r48

Another problem is that the wait() function, which forces thread to wait their turn in the schedule makes use of both mutexes and condition variables. Any thread, therefore, that makes a call to wait() would inadvertently call the the overridden pthread\_mutex\_lock and pthread\_mutex\_unlock functions resulting in a recursive function call and potentially the program crashing or reaching a deadlock.

To overcome this problem, we made use of the dlsym(void* restrict handle, const char* restrict name) function, which looks up the next object with the name specified in the name parameter and returns a reference to the function specified. 

Using these features, we have essentially renamed the real Pthreads API functions so that we can then call those functions from within the functions that we have overridden. This enables us to run a thread and lock and unlock mutexes without having the problem of recursive function calls. So when a user's program makes a call to pthread\_create, our tool will intercept this and then call the real system-implemented version of pthread\_create to run the functions specified by the user in their function call.

Our renamed function calls are shown below:

\lstinputlisting[caption=Renamed Pthreads Functions]{renamed.c}

\subsection{Dynamic Interception}

<<<<<<< .mine
Once P-Rep was working robustly with the wrapper library, we moved on to implementing it using dynamic function intercepting. As described previously, by setting the LD\_PRELOAD variable it is possible to intercept calls to shared libaries at runtime. With this approach there is no need for the program to be recompiled or relinked to make use of P-Rep, as all calls to the Pthreads API within the program will be intercepted by the specified shared library. This is a major advantage to the programmer since it requires no additional effort on their part and means that P-Rep can be used with all existing programs that use the Pthreads API. 
=======
Once the tool was working robustly with the wrapper library, we moved on to implementing it using dynamic function intercepting. 
>>>>>>> .r48

<<<<<<< .mine
One of the main challenges was passing P-Rep the shedule to follow. So that P-Rep has access to the schedule. When the script is run to set up P-Rep various environment variables must be set which can then be accessed by P-Rep to read the schedule and determine what mode of execution it should be run in. The schedules are held in the custom defined KLEE\_SCHED variable. P-Rep will look for the file set in this variable and attempt to read a schedule from it. If the environment variable is not set, or no schedule is found or if the schedule is invalid, then P-Rep will exit. Once the schedule has been read into P-Rep, it can be followed as normal.
=======
As described previously, by setting the LD\_PRELOAD variable it is possible to intercept calls to shared libaries at runtime. With this approach there is no need for the program to be recompiled or relinked to make use of the tool, as all calls to the Pthreads API within the program will be intercepted by the specified shared library. This is a major advantage to the programmer since it requires no additional effort on their part and means that the tool can be used with all existing programs that use the Pthreads API. 
>>>>>>> .r48

<<<<<<< .mine
The obvious problem with the above approach is the setting of excessive environment variables while P-Rep is executing. Failing to unset these environment variables after execution might cause problems if other programs need to use them. This is easily resolved, however, as long as the relevant environment variables are unset after program termination.
=======
One of the main challenges was passing the tool the shedule to follow, so that the tool has access to the schedule. When the script is run to set up the tool various environment variables must be set which can then be accessed by the tool to read the schedule and determine which mode of execution it should be run in. The schedules are held in the custom defined KLEE\_SCHED environment variable. The tool will look for the file set in this variable and attempt to read a schedule from it. If the environment variable is not set, or no schedule is found or if the schedule is of an invalid type, then the tool will exit. Once the schedule has been read into the tool, it can be followed as normal.

The obvious problem with the above approach is the setting of excessive environment variables while the tool is executing. Failing to unset these environment variables after execution might cause problems if other programs need to use them. This is easily resolved, however, as long as the relevant environment variables are unset after program termination.
>>>>>>> .r48

\subsection{Problems}

The main problem we encountered when using dynamic interception to implement P-Rep was with the LD\_PRELOAD environment variable. Unless otherwise specified, setting the LD\_PRELOAD variable will be operating system wide. So any calls by any programs to the Pthreads API will result in those calls being intercepted. Needless to say this can be disastrous for a user if not handled correctly, since this can cause the whole operating system to crash. To remedy this problem, we wrote the script to set the LD\_PRELOAD variable for only the executable which is is passed and to unset the LD\_PRELOAD variable as soon as execution finisheds. This prevents any unneccessary function interception and contains the intercepting to only the program the user wishes to test. 

Another issue we found when using the LD\_PRELOAD was an issues with a program's permissions. In order to prevent a malicious user from intercepting system calls, a program must have the relevant permissions to link and load a dynamic library. The GNU loader will check a program's permission on loading and determine if it is setuid or setgid. The loader will generally assume that a program does not have these permissions and will thus greatly limit its permissions on loading. While this is not problematic when running programs from within the user's own profile, running programs on a remote server via ssh or on any other machine where the owner of the program does not have privileged access will result in a segmentation fault at loadtime.  

There was also a problem when using dlsym() to obtain a handle to function calls. In particular the problem arose when implementing pthread\_cond\_wait(). The dlsym() function makes an unversioned lookup and by default this lookup will match the oldest symbol in the dynamic shared library. If any new features are added to a libary in the future then the dlsym() will still call the older version. Failing to use a versioned dlsym() call resulted in the older version of pthread\_cond\_wait being returned which returned a reference to a different pthread\_cond variable. If the the initial pthread\_cond if located at 0x600d80, for example, then using the unversioned dlsym() function will result in the pthread\_cond variable begin returned at 0x7ffff00008c0. In this scenario, however, the main thread will still assume that the pthread\_cond variable is located at 0x600d80 and so will wait on this variable and receive no signal. To resolve this problem, it was neccessary to use a versioned dlvsym() call to return the GLIBC\_2.3.2 version of the pthread\_cond\_wait() function.

\section{Pthreads API}

This project intercept calls made to thread creation, thread joining, mutex locking and unlocking and waiting on condition variables. The various implementation details for each of these functions are discussed below.

\subsection{pthread\_create() and run\_thread()}

The source code for pthread\_create() using function intercepting is shown below:

\lstinputlisting[caption=Intercepting pthread\_create]{create.c}

<<<<<<< .mine
On the first call to pthread\_create() P-Rep will look for the location of the schedule in an environment variable and read the schedule file using this as its schedule. P-Rep will also check for the relevant flags and set these flags accordingly.
=======
On the first call to pthread\_create() the tool will look for the location of the schedule in an environment variable and read the schedule file and use this as the execution schedule to follow. The tool will also check for the relevant flags and set these flags accordingly.
>>>>>>> .r48

Each time a thread is created a params struct is instantiated to hold the relevant arguments for a thread. 

The params struct is shown below:

\lstinputlisting[caption=The params struct]{params.c}

Params holds a function pointer to the function to be run in the newly created thread, the instrumented ID of the thread and any arguments that need to be passed to the thread function.

Once a thread's parameters have been set up, a call to the real pthread\_create() function is made through the function pointer real\_create. This newly created thread is then told to run the run\_thread() function and is passed the params struct as its arguments. At this point in the execution, the params struct is fully instantiated so the original callee's function can be run through the run\_thread() function.

The run\_thread() function is shown below:
\lstinputlisting[caption=The run\_thread function]{runthread.c}


The first thing the run\_thread() function does is insert the calling thread's ID into the Thread Map. The reason this is done in this function rather than on the call to pthread\_create() is because a call to create a pthread must be done by an existing thread and thus calls to pthread\_self() will return the pthread ID of the thread which called the create function, not the ID of the thread which we are intending to create.

For example, consider the following simple scenario:
\begin{itemize}
\item The main thread with instrumented ID 0 calls pthread\_create()
\item pthread\_self() is called to obtain the ID of the thread to place in the Thread Map
\item Because the call to pthread\_self() was made by the main thread its pthread ID will be returned.
\item Thus there will be two duplicate entries for the pthread ID for the main thread with different instrumented IDs.
\end{itemize} 

For this reason, it far more desirable to insert the ID in the run\_thread() function.

Before a thread can be run it must wait on the schedule. Once it is eligible to be run the function passed in the params struct will be executed. A function might make other calls to Pthread API functions and these are handled accordingly. After a thread has finished its execution. It must increase the schedule step and notify other waiting threads so that they can run.

By creating another thread to run the function that was passed to the initial call to pthread\_create(), we are able to force threads to follow the schedule. Without this approach, threads would have to be run within the call to pthread\_create() and this would cause threads to be forced to wait on each thread creation call, resulting in a lack of proper thread scheduling. The thread created for run\_thread can be viewed as a worker thread, as it is designated to handle the thread scheduling without any other threads having to wait on its completion.

\subsection{pthread\_join()}
Below is the implementation for pthread\_join():

\lstinputlisting[caption=Implementation for pthread\_join]{pthreadjoin.c}

When a call to pthread\_join(pthread\_t p, void** retval) is made, the calling thread will wait for the thread specified in pthread\_t to terminate and any return values are stored in the retval. 

When a call to pthread\_join is made. The calling thread must increase the global step to move the schedule along and notify waiting threads. This is to ensure that other threads can run before the real call to pthread\_join is made, blocking the calling thread. The calling thread must then wait until it is scheduled to run. After waiting the calling thread calls the pthread\_tryjoin function on the ID of the thread it is trying to join. 

The pthread\_tryjoin\_np(pthread\_t tid, void** retval) function performs a non-blocking join with the thread specified in the passed tid. If the thread is busy then an error is returned. P-Rep checks for this error and if the thread is busy, it will step\_and\_notify and wait before calling pthread\_tryjoin again. On the second call to pthread\_tryjoin, the thread should terminate. If it still returns a busy status then it must be assumed that the schedule is invalid and an assertion failure should be raised.

Of course, one of the main disadvantages to this approach is that it reduces the portability of P-Rep. In its current state, pthread\_tryjoin\_np is a non-standard GNU extension and is thus non-portable. 

The positives of using the above approach outweigh the negatives, however, because it prevents the calling thread from blocking. If the calling thread blocked on each call to the pthread\_join there might arise a situation in which all calling threads were blocked and thus a deadlock would occur.



\clearpage
\subsection{pthread\_mutex\_lock() and pthread\_mutex\_unlock()}

Below is the implementation for mutex locking and unlocking:
\lstinputlisting[caption=Implementation of mutex lock and unlock]{lockandunlock.c}

When a thread attempts to lock a mutex, it must first step\_and\_notify to move the schedule along and then wait to determine whether or not other threads are waiting on the mutex lock. 

<<<<<<< .mine
So that threads are no indefinitely blocked when waiting on a mutex, P-Rep makes use of the pthread\_mutex\_trylock function. When a thread calls this function it tries to lock the mutex. wef the mutex if already locked then an error occurs, otherwise the thread successfully locks the mutex. The errors which is usually returned in the EBUSY error value, which indicates that the mutex is already locked. 
=======
So that threads are not indefinitely blocked when waiting on a mutex, the tool makes use of the pthread\_mutex\_trylock function. When a thread calls this function it tries to lock the mutex. If the mutex if already locked then an error occurs, otherwise the thread successfully locks the mutex. The error which is usually returned is the EBUSY error value, which indicates that the mutex is already locked. 
>>>>>>> .r48

<<<<<<< .mine
The important feature of pthread\_mutex\_trylock is that it is a non-blocking call to lock the mutex, so the calling thread will continue execution if an EBUSY value is returned. wef, instead of using pthread\_mutex\_trylock, P-Rep used the standard mutex lock function: pthread\_mutex\_lock, threads might end up being indefinitely blocked waiting on the schedule to obtain the mutex lock, thus leading to a global deadlock. 
=======
The important feature of pthread\_mutex\_trylock is that it is a non-blocking call to lock the mutex, so the calling thread will continue execution if an EBUSY value is returned. If, instead of using pthread\_mutex\_trylock, the tool used the standard mutex lock function, pthread\_mutex\_lock, threads might end up being indefinitely blocked waiting on the schedule to obtain the mutex lock, thus leading to a global deadlock. 
>>>>>>> .r48

Unlocking a mutex requires a thread only to step\_and\_notify and wait. Once ready, a thread simply makes the call to the real mutex\_unlock through the dlsym() handle. The overridden function can then return the result of this unlock.


\subsection{pthread\_cond\_wait()}

Below is the implementation for pthread\_cond\_wait:

\lstinputlisting[caption=Implementation of pthread\_cond\_wait]{condwait.c}

When a thread makes a call to pthread\_cond\_wait it always blocks, and on return it should have obtained the mutex lock it was originally trying to obtain in the call to pthread\_cond\_wait. 

In the intercepted version of pthread\_cond\_wait, a thread first calls step\_and\_notify and then makes a call to unlock the mutex. This is to ensure that it does enter a wait state with the mutex already locked. If the calling thread did not unlock the mutex on entry to the function call and it already had the mutex locked then other threads would be forced to wait, potentially leading to a deadlock. A call to unlock a mutex that a thread does not already have ownership of will result in a failure with the EPERM result. This means that it is viable for a thread to attempt to unlock a mutex it does not already have locked with no adverse repercussions. 

Once a thread has obtained the mutex lock it can resume its processing and then step\_and\_notify before exiting the function call.



\clearpage
\subsection{pthread\_cond\_timedwait()}

The implementation for pthread\_cond\_timedwait() is shown below:
\lstinputlisting[caption=Implementation of pthread\_cond\_timedwait]{timedwait.c}

We have implemented pthread\_cond\_timedwait by using the already overridden pthread\_mutex\_lock and pthread\_mutex\_unlock. The reason for this is to ensure synchronisation occurs before the thread obtains the lock and also when it releases the lock. We assume that if the thread does not obtain the lock with either of these two calls, then it has timed out.

<<<<<<< .mine
This approach limits the effectiveness of the timed wait function, since it will always return ETIMEDOUT. For the sake of our implementation, however, it proved enough to lock and unlock the mutex and return ETIMEDOUT since for the programs we tested which made use of pthread\_cond\_timedwait ignored the return value anyway. Of course, any program that should use the return would not work with our tool but for the purposes of getting P-Rep to work in our testing environment this was appropriate.
=======
This approach limits the effectiveness of the timed wait function, since it will always return ETIMEDOUT. For the sake of our implementation, however, it proved enough to lock and unlock the mutex and return ETIMEDOUT ,since for the programs we tested which made use of pthread\_cond\_timedwait ignored the return value anyway. Of course, any program that should use the return would not work with our tool but for the purposes of getting the tool to work in our testing environment this was appropriate.
>>>>>>> .r48

\subsection{Problems}

One of the main problems we encountered when implementing the Pthread functions was in thread joining. There were numerous occasions when a thread could interrupt another thread before it had finished executing the run\_thread function and return EBUSY in the call to pthread\_tryjoin\_np. If any call to pthread\_tryjoin\_np returned EBUSY twice, then we would get an assertion failure and P-Rep would cease execution. 

Taking this approach guarantees the integrity of the schedule P-Rep has been passed. If the thread has failed to join afte two attempts, the schedule can be deemed inaccurate, since they threads should have been forced to finish execution when the join function was called. If the thread is still active, then the schedule is inaccurate and P-Rep will not be able to progress past a certain point. If the schedule is inaccurate then P-Rep will fail and raise an exception.

This problem was resolved by ensuring that the schedules the tool was passed were accurate.


\chapter{Testing and Evaluation}

<<<<<<< .mine
This section covers the different tests we used to test the overall effectiveness of P-Rep and to evaluate its performance under a variety of different scenarios.
=======
This section covers the different tests we used to evaluate the overall effectiveness of the tool and to assess its performance under a variety of different scenarios.
>>>>>>> .r48

\section{Testing Method}

<<<<<<< .mine
In order to test P-Rep, we have taken three testing approaches. The first is running P-Rep alongside some hand-written tests with schedules generated by KLEEE-THREADS. The second approach was taking the existing test suites used by KLEE-THREADS to generate schedules and then run these existing programs with P-Rep. The third set of tests are to demonstrate the stability and efficiency of P-Rep and these are variety of hand-written scenarios.
=======
In order to test the tool, we used avariety of testing methods. Our primary aim in our testing was to ensure that the tool followed the schedules it was passed accurately. We wanted to assess how well it performed with schedules that KLEETHREADS output, as well as how it performed with schedules we had written ourselves. We also wanted to ensure that it worked with a variety of complex programs, with threads spawning other threads etc. to see if the tool could maintain its integrity. FInally we wanted to test the speed of the tool and evaluate our decision to use a shim library to implement the deterministic replay feature of our tool.
>>>>>>> .r48

\section{Hand-written Tests}

<<<<<<< .mine
In order to test that P-Rep works as  expected, we wrote a number of simple hand-written tests to determine if the P-Rep will follow schedules faithfully.  In all of the tests P-Rep followed the schedules output by KLEE-THREADS. Under almost every scenario, KLEE-THREADS output a large amount of different schedules for any given executable.
=======
In order to test that the tool worked as  expected, we wrote a number of simple hand-written tests to determine if the the tool followed schedules faithfully.  In all of the tests the tool followed the schedules output by KLEETHREADS. Under almost every scenario, KLEETHREADS output a large amount of different schedules for any given executable.
>>>>>>> .r48

<<<<<<< .mine
In order to determine in the passed schedule has been followed faithully by P-Rep, we have modified P-Rep to build an array of thread ID in the order in which they were executed. we then compare the build schedule with the original schedule that was passed and if they match then we know that P-Rep has followed the schedule faithfully. we altered the step\_and\_notify function to log the instrumented ID of the calling thread each time it is called. Since step\_and\_notify is called at every synchronisation point, it seemed suitable to use this approach to build the followed schedule. 
=======
In order to determine if the passed schedule has been followed faithully by the tool, we have modified the tool to build an array of thread IDs in the order in which they were executed. We then compare the built schedule with the original schedule and if they match then we know that the tool has followed the schedule faithfully. We altered the step\_and\_notify function to log the instrumented ID of the calling thread each time it is called. Since step\_and\_notify is called at every synchronisation point, it seemed suitable to use this approach to build the schedule dynamically. 
>>>>>>> .r48

<<<<<<< .mine
All of the hand-written tests were run in P-Rep's FOLLOW\_AND\_TERMINATE mode so that the end of the schedule could be reached and then compared against the schedule the that was generated on execution. Testing the accuracy of P-Rep in the other modes cause problems. Testing in its default mode will result in P-Rep hanging and no further progress being made, thus it would be impossible to accurately replay the schedule P-Rep has followed, since there is no way to extract the followed schedule. 
=======
All of the hand-written tests were run in the tool's FOLLOW\_AND\_TERMINATE mode so that the end of the schedule could be reached and then the generated schedule compared with the passed schedule. Testing the accuracy of the tool in the other modes cause problems. Testing in its default mode will result in the tool hanging and no further progress being made, thus it would be impossible to accurately replay the schedule the tool has followed, since there is no way to extract the followed schedule. 
>>>>>>> .r48

<<<<<<< .mine
To determine whether or not P-Rep has faithfully followed the schedule or not, at the end of a given execution P-Rep will compare the two schedules (the one it was passed and the one it generated) and throw an error code if the schedules do not match or else it will terminate normally. Using this method allows the use of a simple script to test if P-Rep has terminated successfuly.
=======
To determine whether or not the tool has faithfully followed the schedule or not, at the end of a given execution the tool will compare the two schedules (the one it was passed and the one it generated) and throw an error code if the schedules do not match or else it will terminate normally.
>>>>>>> .r48



To test the basic effectiveness of P-Rep, we tested it with a simple program that makes use of all of the Pthread API functions that we have overridden. 

The program we tested under KLEETHREADS is shown below:
\lstinputlisting[caption=Simple program using all overridden features]{condtest.c}

The way in which the program performs is fairly self-exlpanatory. The only thing of note is the assert(false) at the end of the program on line 52. The purpose of having this is to force KLEETHREADS to generate a schedule which will find this assertion failure so that we can generate longer schedules to test the program, rather than shorter schedules that only run to the first bug and no further.

<<<<<<< .mine
KLEE-THREADS generated 131 schedules leading to bugs when run on this program. we did not run P-Rep with every schedule but instead opted to test it with a variety of schedules a number of times. In total, we tested 20 of the generated schedules 100 times each and examined the results. To determine which schedules we should use, we used a random number generator \footnote{http://www.random.org/} to generate random numbers between 1 and 131 and then tested the schedules with the matching numbers. This was to guarantee fairness to ensure that we could not deliberately fix the schedules to suit my tool.
=======
KLEETHREADS generated 131 schedules leading to bugs when run on this program. We did not run the tool with every schedule but instead opted to test it with a variety of schedules a number of times. In total, we tested 20 of the generated schedules 10 times each and examined the results. To determine which schedules we should use, we used a random number generator \footnote{http://www.random.org/} to generate random numbers between 1 and 131 and then tested the schedules with the matching numbers. This was to guarantee fairness.
>>>>>>> .r48


\clearpage
The results are shown below:
\input{condtestresults.tex}

<<<<<<< .mine
In all of the tests we ran P-Rep followed the schedule as expected. This, in itself, is not particularly surprising (or exciting) and the purpose of running these controlled tests was merely to demonstrate that P-Rep worked well in a predictable environment and that all of the different API calls had been implemented correctly.
=======
In all of the tests we ran the tool followed the schedule as expected. This, in itself, is not particularly surprising (or exciting) and the purpose of running these controlled tests was merely to demonstrate that the tool worked well in a predictable environment and that all of the different API calls had been implemented correctly. This was demonstrated by the tool's accuracy.
>>>>>>> .r48

\subsection{Deadlock Tests}

We also tested P-Rep with a program that leads to a deadlock. This test was written in conjunction with KLEE-THREADS and aims to force the program to deadlock. 

The program is shown below:

\lstinputlisting[caption=A program leading to deadlock]{deadlocktest.c}


The program is more complicated and diverse than the previous one and was written to test the limits of P-Rep by generating longer schedules to see what errors occurred under each condition.

Running KLEETHREADS with the following options: (-emit-all-errors -happens-before-cache -scheduler-preemption-bound=1 -fail-on-race) results in 49 schedules being generated. 

Rather than using a random number generator to test the results, we opted to run tests on the first 10 schedules to check for any errors in both our recording process and P-Rep's execution order.
\clearpage
\input{deadlocktestres.tex}

<<<<<<< .mine
As can be observed from the results, P-Rep performed well under harsher test conditions. With a longer schedule, P-Rep succesfully followed it until the end and performed well with the more complex execution structure and P-Rep was able to maintain the integrity of its Thread Map and start and stop threads on demand.
=======
As can be observed from the results, the tool performed well under harsher test conditions. With a longer schedule, the tool succesfully followed it until the end and performed well with the more complex execution structure and the tool was able to maintain the integrity of the thread map, and was able to start and stop threads on demand.
>>>>>>> .r48

<<<<<<< .mine
These tests demonstrate that P-Rep is able to continue performing and providing deterministic replay with arbtitrarily long schedules. This is a critical feature of P-Rep, since more complex schedules will inevitably produce much large execution schedules and we would want P-Rep to perform under a multitude of conditions.
=======
These tests demonstrate that the tool is able to continue performing and providing deterministic replay with arbtitrarily long schedules. This is a critical feature of the tool, since more complex schedules will inevitably produce much large execution schedules and we would want the tool to perform well under a multitude of conditions.
>>>>>>> .r48

We can also observe from these results that P-Rep is accurately following the schedules it has been passed, rather than following some other thread ordering. It is essential that P-Rep follows its passed schedule accurately in order to provide deterministic replay. These results above demonstrate P-Rep's effectiveness.

\subsection{Testing RECORD mode}

To test the record mode, we wrote a simple program that might lead to a deadlock under certain scenarios. We then ran the program in P-Rep's record mode to record a schedule that led to a deadlock. Once we had generated this schedule, we could rerun the program with this schedule and see if it led to a deadlock. If by running P-Rep with the generated schedule we recorded the same output, then we could assume that P-Rep's RECORD mode was working correctly.

To perform this test we used a version of the classic Dining Philosophers problem\cite{dining}. We also tested the record mode with the Producer/Consumers problem. 


<<<<<<< .mine
Our test conditions for both were as follows. We first checked to see if P-Rep did detect a deadlock when the deadlock occurred, we then checked to see if P-Rep faithfully followed the schedule that led to a deadlock. Most of the scenarios that we ran created schedules that were up to 200 steps longs. This was advantageous for us since it meant that we could simlutaneously test the replay robustness of P-Rep with longer schedules.
=======
Our test conditions for both were as follows. We first checked to see if the tool did detect a deadlock when the deadlock occurred, we then checked to see if the tool faithfully followed the schedule that led to a deadlock. Most of the scenarios that we ran created schedules that were up to 200 steps long. This was advantageous for us since it meant that we could simlutaneously test the replay robustness of the tool with longer schedules as well as assess the tool's performance with longet schedules.
>>>>>>> .r48

An implementation fo the Dining Philosophers problem is shown below:
\lstinputlisting[caption=Dining Philosophers Problem]{dp.c}

We had to run the program several times to ensure that we eventually had a deadlock. We ran five tests with different schedules P-Rep found to ensure that each one did indeed lead to a deadlock. 

Our results our shown below:
\input{recordeads.tex}
 
<<<<<<< .mine
As you can see on the 4th and 5th schedule that we ran, P-Rep did not reach a deadlock. This suggests that the recording mode of P-Rep is not as precise in its recording as it could be. 
=======
As we can see on the 4th and 5th schedule that we ran, the tool did not reach a deadlock. This suggests that the record mode of the tool is not as precise in its recording as it could be. 
>>>>>>> .r48

<<<<<<< .mine
Since the program itself is not data race free, there may have been very specific synchronizations that it missed and thus resulted in the produced schedule not being entirely accurate. A program with data races would cause problems for our tool's record mode, since it would not be able to accurately the detect the precise order of thread execution in the situation in which the race occurred. By their very nature, data races are indeterminate, so our tool would only be able to provide a certain level of determinism in such a data race. As a result of this indeterminism, our tool might output a schedule that was slightly different from the schedule that actually executed, thus resulting in a different execution path. This is why P-Rep did not deadlock on every occasion.
=======
Since the program itself is not data race free, there may have been very specific synchronizations that it missed and thus resulted in the produced schedule not being entirely accurate. A program with data races would cause problems for our tool's record mode, since it would not be able to accurately the detect the precise order of thread execution in the situation in which the race occurred. By their very nature, data races are indeterminate, so our tool would only be able to provide a certain level of determinism in such a data race. As a result of this indeterminism, our tool might output a schedule that was slightly different from the actual order of execution, thus resulting in a different execution path. This is why the tool did not deadlock on every occasion.
>>>>>>> .r48

This shows us that while our tool can be effective in its execution traces, it also can produce false positives. The final schedules that P-Rep produces, however, should not be that different from the actual execution that P-Rep followed, since it will have only have been the slightest misordering that would have led to a different schedule.

Where our tool would not be effective would be in a program that does not protect its shared variables with the Pthreads API.

For example consider the following code snippet:

\lstinputlisting[caption=Unprotected Shared Variable]{unipro.c}

Assume that one or more threads are running the alter function in this execution. As you can see the global variable `j' is not protected by any mutexes, therefore the threads that alter this variable will not be recorded and this race conditon will be completely ignored by our tool. Since our tool is meant to be primarily a replay tool used for debugging purposes and is primarily intended to aid in debugging programs that make use of the Pthreads API, we do not consider this that much of an issue for the tool in its current state. The purpose of this project has not been to implement a robust record tool, but rather a sturdy replay tool and this is something we have achieved.

We also tested P-Rep's record feature with the Producers/Consumers Problem.

An implementation of the Producers/Consumers Problem is shown below:
\lstinputlisting[caption=Producers/Consumers Problem]{producers.c}

The difference between this program and the Dining Philosophers program is that it will always deadlock. Despite this, it will not necessarily be the same execution trace that leads to the deadlock and as can be observed from our reuslts, our tool found a different schedule for each deadlock it encountered. 

<<<<<<< .mine
Our results from running P-Rep in its record mode five times on this program are shown below:
=======
Our results from running the tool in its record mode 5 times on this program are shown below:
>>>>>>> .r48

%%\input{newres.tex}

<<<<<<< .mine
As you can P-Rep was much more effective in producing schedules that led to a deadlock with this program. The reason for this is that there are no data races in the program and therefore P-Rep is able to produce a much more accurate execution trace and one that always results in a deadlock at the end of the schedule.
=======
As we can the tool was much more effective in producing schedules that led to a deadlock with this program. The reason for this is that there are no data races in the program and therefore the tool is able to produce a much more accurate execution trace and one that always results in a deadlock at the end of the schedule.
>>>>>>> .r48

<<<<<<< .mine
\section{KLEE-THREADS Test Suite}
We wrote several of these tests, ran KLEE-THREADS on these programs and then ran the original programs with P-Rep.
=======
>>>>>>> .r48

\section{Efficiency Tests}

We have conducted efficiency tests to show how P-Rep performs under various situations, but also to demonstrate the minimal overhead that is incurred by using function interception. A system call is typically expensive for a program to make anyway, so intercepting these system calls and forcing certain schedules to be followed incurs a minimal additional overhead to the original system call. 

\subsection{Comparison of Wrapper Library and Function Intercepting Efficiency}

<<<<<<< .mine
There appears to be a small difference in efficiency between using a wrapper library or function intercepting to implement P-Rep. In order to measure a difference between the two implementation of P-Rep we wrote a program that creates four threads each running the same function. In the function, the threads must lock a mutex, modify a global variable, open a file, write to it and close it, and then open, write to and close another file 10000 times within a for loop. After exiting the for loop, the thread must unlock the mutex and return.
=======
There appears to be a small difference in efficiency between using a wrapper library and function intercepting to implement the tool. In order to measure a difference between the two implementations of the tool we wrote a program that creates four threads each running the same function. In the function, the threads must lock a mutex, modify a global variable, open a file, write to it and close it, and then open, write to and close another file 10000 times within a for loop. After exiting the for loop, the thread must unlock the mutex and return.
>>>>>>> .r48

We wrote the programs in this way so that their would be a significant amount of computation for each thread to perform. If the programs terminated too quickly without performing some file I/O or some other expensive operation, the program's would be executed too quickly for us to time accurately.


The version using the wrapper library is shown below:
\lstinputlisting[caption=Wrapper Library Speed Test]{wrapperrace.c}


The version using function intercepting in shown below:
\lstinputlisting[caption=Function Interception Speed Test]{interceptrace.c}

<<<<<<< .mine
Since the version of P-Rep which uses function intercepting is set up using a python script, we set the environment variables manually for each execution so that there would be no overhead incurred by using the Python script. I/O also requires system calls so we executed both versions with no output to the standard output other than the final value of GLOB.
=======
Since the version of the tool which uses function intercepting is set up using a Python script, we set the environment variables manually for each execution so that there would be no overhead incurred by using the Python script. I/O also requires system calls so we executed both versions with no output to the standard output other than the final value of GLOB.
>>>>>>> .r48


<<<<<<< .mine
We ran the tests in P-Rep's normal mode of execution. The schedule we passed P-Rep was handwritten. We wrote the schedule by hand to ensure that the programs finished execution. KLEE-THREADS would have generated a lot of possible execution paths for this program and to the output might have varied for each version of P-Rep. By writing this schedule by hand we were able to guarantee that the schedule would work with both implementations and also that both version would be executing in the same order.
=======
We ran the tests in the tool's normal mode of execution. The schedule we passed the tool was handwritten. We wrote the schedule by hand to ensure that the programs finished execution. KLEETHREADS would have generated a lot of possible execution paths for this program and the output might have varied for each version of the tool. By writing this schedule by hand we were able to guarantee that the schedule would work with both implementations and also that both versions would be executing in the same order.
>>>>>>> .r48

We ran the program with the same schedule:

[0,0,0,0,1,1,1,1,2,2,2,2,3,3,3,3,4,4,4,4,0,0,0,0,0,1,2,4,3,0,0,0,0,0,0,0,0] 

<<<<<<< .mine
10 times with each implementation of P-Rep to see which version of P-Rep was faster on average. The average execution speeds are shown below for the full results see Appendix A:
=======
10 times with each implementation of the tool to see which version of the tool was faster on average. 
>>>>>>> .r48

\clearpage
The average execution speeds are shown below, for the full results see Appendix A:
\input{averagespeed.tex}

<<<<<<< .mine
As we can see the version of P-Rep which uses the wrapper library is marginally faster than the version which uses function interception. We put this difference in speed to the fact that the program that uses our shared library has to load the library and make additional calls to dlysym() to override the functionality of the intercepted Pthreads functions, while the version of P-Rep which uses the wrapper library only needs to lookup statically linked functions.
=======
As we can see the version of the tool which uses the wrapper library is marginally faster than the version which uses function interception. We put this difference in speed down to the fact that the program that uses our shared library has to load the library and make additional calls to dlsym() to override the functionality of the intercepted Pthreads functions, while the version of the tool which uses the wrapper library only needs to lookup statically linked functions.
>>>>>>> .r48

<<<<<<< .mine
While the wrapper library performs better that the function interceptin version of P-Rep, we still maintain that implementing P-Rep as a shim is much more effective than implementing it as a wrapper libary. While the wrapper library is faster, it lacks the immediate convenience of the version which uses function intercepting. To use the wrapper library in a production environment, we would have to instrument the user's source code to replace their alls to the Pthreads API with our calls to the wrapper library. We would also be required to to recompile all the programs that used the Pthreads API, so that they made use of our wrapper library instead of the original Pthreads API. For this reason, using function interception is far more desirable than using a wrapper library.
=======
While the wrapper library performs better that the function interception version of the tool, we still maintain that implementing the tool as a shim is much more effective than implementing it as a wrapper libary. While the wrapper library is faster, it lacks the immediate convenience of the version which uses function intercepting. To use the wrapper library in a production environment, we would have to instrument the user's source code to replace their calls to the Pthreads API with our calls to the wrapper library. We would also be required to to recompile all the programs that used the Pthreads API, so that they made use of our wrapper library instead of the original Pthreads API. For this reason, using function interception is far more desirable than using a wrapper library.
>>>>>>> .r48

\subsection{Existing Software Tests}

To demonstrate P-Rep's minimal overhead, we have taken programs which have demonstrated an increase in execution speed by using the Pthreads library and then generated schedules for these programs, timed them without using P-Rep and with using P-Rep and then compared the differences.

We ran our tool with Parallel Bzip2 (pbzip2). To do this we generated large trace schedules using KLEETHREADS to feed to the tool to follow while pbzip2 compressed a 135MB tar ball which we created. pbzip2 achieves near linear speed-up on multiprocessor machines. \footnote{http://compression.ca/pbzip2/} 

We first ran a test using pbzip2 without out tool and timing how long it took to zip our 135MB tarball. We then performed the exactly the same operation, except this time using pbzip2 with our tool. We wanted to observe several things in this experiment. The first was the difference in speed between the zip operation that used our tool and the zip operation that ran without our tool. The second was to test the tool's effectiveness in a production ready environment. KLEETHREADS produced very large schedules of over 1500 in most cases, so this was an excellent to show that tool can handle longer schedules. 

The difference in execution speed of the two tools is shown in the table below:
%%\input{pvsn.c}


\section{Portability}

Perhaps one of the main problems with P-Rep in its current state is portability. While P-Rep has been designed to work with the Pthreads API and thus theoretically with any POSIX compliant machine. This is not the case unfortunately. 

\subsection{Mac OS X}
On a Mac, one of the issues was that the OS X operating system keeps a system implementation of the wait() function. This caused our wait() function to be ignored since wait() has already been defined. We fixed this by simply redefining the wait() function to be my\_wait().

Another problem we faced on the Mac was in compilation with finding the location of ``malloc.h". To fix this all we needed to do alter our Makefile to specify the correct location of ``malloc.h"

While these two issues were trivial to fix, we had further problems with compilation in pthread\_tryjoin\_np. As expected, this function is not portable and has no equivalent implementation on the OS X operating system.

The function dlvsym() is also not supported on the Mac operating system. Rewriting P-Rep to use dlsym() in the pthread\_cond\_wait caused the same problem we had when originally implementing the pthread\_cond\_wait function in section: 4.3.3. 

\subsection{BSD}

We used FreeBSD 9.0 runnning in VirtualBox to test our tool's portability to a BSD system. The GNU C Libary (GLIBC) is not supported on FreeBSD so not all of our tool's features are supported on this platform. Specifically pthread\_tryjoin\_np is not supported on the FreeBSD platform, so not all of the functionality of our tool was available on the FreeBSD system we tested with.

After removing our implementations of pthread\_join, we were able to get the tool working on the virtualised FreeBSD system. All of the other overridden Pthread functions worked well on the FreeBSD operating system and this was an encouraging results. 

While not every feature of our tool could be implemented on a FreeBSD system, we were nevertheless able to get the tool working for the Pthread functions that were portable and the tool worked as expected for these functions.

\section{Overall Evaluation}

<<<<<<< .mine
P-Rep is most effective when used in its replay mode. As we have shown from the results above, it will accurately follow any schedule that it is passed. We believe that the reason for this effectiveness is in its simplicity. By using only one global semaphore to schedule threads, we eliminate the complexity that would be involved in interleaving thread execution. 
=======
The tool is most effective when used in its replay mode. As we have shown from the results above, it will accurately follow any schedule that it is passed. We believe that the reason for this effectiveness is in its simplicity. By using only one global semaphore to schedule threads, we eliminate the complexity that would be involved in manually interleaving thread execution. 
>>>>>>> .r48

P-Rep is able to replay a full schedule for any concurrent C program that uses the Pthreads API and makes use of the functions we have overridden. Many programmers only use a small fraction of the Pthreads API, making use of mutexes and conidtion variables. Therefore, our tool can be used with many existing concurrent C programs to replay any given schedule it is passed.

While our tool is primarily designed to work with KLEETHREADS, we have shown that it will in fact follow any schedule it is passed accurately. This is a highly desirable feature, since it means it can be used in a number of environments. A programmer might wish to incrementally observe the output of their program by slowly incrementing a schedule and observing the different states the program enters. Our tool can be used in conjunction with \textsf{gdb} by manually setting the environment variables to point to the schedule location and the LD\_PRELOAD environment variable. Using this technique a programmer can debug their program normally using breakpoints and other tools, while forcing it to follow a particular thread schedule. Once the end of the schedule is reached, the programmer can observe and record the program's state. 

Having the ability to maintain such fine-grained control over a concurrent program's execution state is highly desirable, since normally when debugging with a tool like \textsf{gdb} the program's thread ordering will be completely different in each execution. Also the debugger might slow down the execution speed, resulting in data races being missed or occurring in a different order or not occurrin at all. Our tool removes this nondeterminism and adds a level of complete determinism to concurrent software, which provides a programmer with an invaluable understanding into the execution of their program.

Finally, we have demonstrated our tool to be higly robust in its replay feature. We have shown that it scales well under a number of complex scenarios and is able to follow longer schedules with minimal overhead. The fact that all of this can be achieved with absolutely no modification to the original executables is highly encouraging since it means our tool can be used `out of the box,' as it were, and a programmer can immediately start testing schedules and observing results on any of their existing programs that use the Pthreads API.

Our tool provide determinism to nondeterministic programs and does so in a robust, scaleable and simple fashion.


\chapter{Conclusion}


\section{Achievements}

We have achieved all of the initial goals for the project as well as adding a record mode to detect deadlock and record the schedule that led to that deadlock. 

What is unique about our tool is that it can be run either with tools that provide execution traces to programs or independently with any schedule the programmer chooses to provide. Using P-Rep solely for its replay feature it particularly useful when attempting to find concurrent software bugs. The programmer can slowly increment their schedule and keep re-running their program with our tool ot observe how different schedules will effect the overall outcome of their program.

<<<<<<< .mine
Combined with its FOLLOW\_AND\_RESUME mode (in which P-Rep runs to the end of a schedule and resumes normal concurrent execution) this makes P-Rep even more useful since a proogrammer can force a certain schedule to be followed up to a certain point and then observe how initial deterministic thread scheduling can effect the final non-deterministic state of a program.
=======
Combined with its FOLLOW\_AND\_RESUME mode (in which the tool runs to the end of a schedule and resumes normal concurrent execution) this makes the tool even more useful since a programmer can force a certain schedule to be followed up to a certain point and then observe how initial deterministic thread scheduling can effect the final non-deterministic state of a program.
>>>>>>> .r48

Even multi-threaded programs that are data-race free can have non-deterministic behaviour, since we cannot be sure which threads are executing when. Our tool provides an excellent way to provide determinism to these non-deterministic programs and thus can be used to trace all sorts of bugs, not just traditional concurrency bugs. For example, a programmer may have trouble tracing a segmentation fault that only occurs under certain conditions. By using our tool and gradually building a schedule to experiment with different execution routes, the programmer will be able to track down and fix the segmentation fault, or any other bug.

We believe that this the most unique property of our tool. The ability to add deterministic replay to concurrent C programs independent of any record tools, is something which is of great use to the developer. It provides them with a toolbox to find and fix bugs without having to recompile or relink their executables. This is something that will prove more useful for larger programs or programs with longer compile times.


\section{Future Work}
<<<<<<< .mine
The most obvious extension to P-Rep is to continue implementing the rest of the Pthreads API. While it is a large API, we think implementing the whole API is feasible and would result in a robust and reliable tool that could be used with all concurrent C programs that use the Pthreads API to provide deterministic replay. In combination with KLEE-THREADS, this would a create a full record/replay suite to concurrent C programs and would prove an invaluable tool to developers developing concurrent software in C.
=======
The most obvious extension to the tool is to finish implementing the rest of the Pthreads API. While it is a large API, we think implementing the whole API is feasible and would result in a robust and reliable tool that could be used with all concurrent C programs that use the Pthreads API to provide deterministic replay. In combination with KLEETHREADS, this would a create a full record/replay suite for concurrent C programs and would prove an invaluable tool to developers developing concurrent software in C.
>>>>>>> .r48

Another possible extension to P-Rep would be to give a more thorough execution trace to the bug. In the its current state, P-Rep does not really provide too in-depth a trace after termination to the bug. So as an added, extension it would be desirable to provide the user with a stack trace or clear path to the fault after the program's termination. 

<<<<<<< .mine
Also when P-Rep runs in its default execution state, it simply hangs on once it reaches the end of a schedule and this is somewhat unhelpful for users of P-Rep who might want to print a stack trace to help determine the state of variables at the program's termination. To this end, we think it would desirable to work towards integrating P-Rep with an existing debugger such as gdb. This would be highly desirable since it would provide the programmer with the ability to trace concurrency bugs but also to use all of P-Reps that gdb provides as well.
=======
In addition, when the tool runs in its default execution state, it simply hangs once it reaches the end of a schedule and this is somewhat unhelpful for users of the tool who might want to print a stack trace to help determine the state of variables at the program's termination. To this end, we think it would desirable to work towards integrating the tool with an existing debugger such as \textsf{gdb}. This would be highly desirable since it would provide the programmer with the ability to trace concurrency bugs but also to use all of the tools that \textsf{gdb} provides as well.
>>>>>>> .r48

<<<<<<< .mine
The final extension which we considered but did not have time to implement was extending P-Rep's record feature to make it more robust in programs that have data races. In its current state the record mode will detect a deadlock and output the schedule that to that deadlock. The schedule it produces will not always be accurate if the program has data races, since by their very nature the specific thread ordering of data races is difficult to trace. P-Rep will only offer a trace to data races if the variable is protected by a mutex or a condition variable. Variables that are not protected by the Pthreads API will be ignored, since P-Rep will only log the thread ordering if a thread calls the step\_and\_notify() function.  If a data race occurs with no synchronisation then P-Rep will not notice it and the trace it produced might not accurately represent the actual schedule of execution. Fixing this would be a desirable extension to P-Rep.
=======
The final extension which we considered but did not have time to implement was extending the tool's record feature to make it more robust in programs that have data races. In its current state the record mode will detect a deadlock and output the schedule that led to the deadlock. The schedule it produces will not always be accurate if the program has data races, since by their very nature the specific thread ordering of data races is difficult to trace. The tool will only offer a trace to data races if the variable is protected by a mutex or a condition variable. Variables that are not protected by the Pthreads API will be ignored, since the tool will only log the thread ordering if a thread calls the step\_and\_notify() function.  If a data race occurs with no synchronisation then the tool will not notice it and the trace it produced might not accurately represent the actual schedule of execution. Fixing this would be a desirable extension to the tool, as it would add a full record feature.
>>>>>>> .r48




\bibliography{mybib}{}
\bibliographystyle{ieeetr}

\appendix
\chapter{Appendix A}

\input{interceptfullresults.tex}
\input{wrapperfullresults.tex}
\clearpage

\lstinputlisting[caption=Python Script to Launch Tool]{tool.py}
\end{document}